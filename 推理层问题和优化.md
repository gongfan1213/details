把应用的状态转换成为连续向量，直接嵌入到模型的注意力层当中，实现隐士检索

推理 输入问题和输出答案之间的中间步骤，生成token，

任何可以通过布尔电路解决的问题，都可以通过生成中间的token来恒定大小的transformer模型来解决的


逻辑电路的大小决定了解决问题的能力，

语言模型已经具备了推理的能力，关键在于解码的过程

链式推理解码：如果我们多考虑一些候选的答案，但是如果我们多考虑一些候选的答案，而不是只选择一个最可能的候选答案，模型就能产生一个更佳正确的答案。

超越贪婪解码，检查更多的生成候选，

选择最后答案置信度最高的候选。

逐步思考：

不需要找到类似的实例，只需要说让我们一步步思考就会有奇迹出现的但是表现比少量实例差的多的

sft泛化能力有限

1.解决人类标注错误的问题，机器生辰好的数据可能优于人类构建的数据

openai response API

<img width="919" height="777" alt="image" src="https://github.com/user-attachments/assets/dd1de81d-570b-4051-8e23-0a550d25603a" />

一旦更好的模型生成了响应或者训练数据，模型就可以自我改进

直接优化我们想要的东西，

如果我们想要构建一个用于推理的模型，或者只是一般用于生成有趣1的内容的，我们就u需要优化衡量生成质量的指标，一旦你有了一个度量的标准，我们所需要做的计算该度量的标准的梯度并且进行反响的传播

假设模型是一个先验的模型，我们需要最大化该指标的期望值，我们需要进行采样来计算期望值，策略梯度的原因。


真正的扩展只有两个过程，一个是学习，另外一个是搜索的，学习是可以扩展的。

RL fnetuning的优势在于它的泛化能力很好的，




推理api staleless
