### 面试题：总体架构与数据流

#### Q1：项目的整体架构由哪些模块构成？各自职责是什么？
**标准回答**：
- UI（`ui/`）：React+Vite 前端，提供聊天式交互与任务/文件可视化；通过 `querySSE.ts` 与后端建立 SSE 流。
- 后端（`genie-backend/`）：Spring Boot 提供 `/web/api/v1/gpt/queryAgentStreamIncr`（SSE）与 `/AutoAgent`（SSE）等接口，负责多智能体规划/执行/总结与工具编排；整合 LLM、Python 工具服务与 MCP 客户端。
- Python 工具（`genie-tool/`）：FastAPI 提供 `/v1/tool/*` 与 `/v1/file_tool/*`，支持代码执行、报告生成、深度搜索、文件上传/预览/下载；流式返回 `EventSourceResponse`。
- MCP 客户端（`genie-client/`）：FastAPI 提供 `/v1/tool/list`、`/v1/tool/call`，与外部 MCP Server 进行 SSE 交互，供后端动态扩展能力。

#### Q2：一次完整请求的端到端时序如何？
**标准回答**：
1) 前端 `ChatView` 组装 `sessionId/requestId/query/deepThink/outputStyle`，通过 `POST /web/api/v1/gpt/queryAgentStreamIncr` 建立 SSE。
2) 后端将请求交给多智能体编排（必要时内部调用 `/AutoAgent`），在执行过程中按需调用 Python 工具与 MCP 客户端。
3) 过程事件与最终结果以 SSE 增量推送给前端（含 `heartbeat`）。
4) 前端以 `combineData/handleTaskData` 将事件归并到 UI 状态并渲染任务面板与文件预览。

#### Q3：为什么选择 SSE 而不是 WebSocket？
**标准回答**：
- SSE 对于服务端单向推送、低复杂度长连接非常合适；浏览器原生支持，HTTP 友好，后端实现简单。
- 本项目主要是从服务端向前端持续推送增量文本/任务事件，客户端上行很少，使用 SSE 更轻量。
- 若需要双向低延迟通信或大规模房间广播，WebSocket 更合适，但当前场景下 SSE 的工程复杂度和成本更低。

#### Q4：各模块的默认端口与环境变量关键项是什么？
**标准回答**：
- 端口：UI `3000`，后端 `8080`，工具 `1601`，MCP 客户端 `8188`。
- 前端：`SERVICE_BASE_URL` 指向后端；Vite 代理 `/web` 到该地址。
- 后端：`application.yml` 中 `llm.default.*` 与 `autobots.*`；工具/MCP 地址 `code_interpreter_url/deep_search_url/mcp_client_url`。
- 工具：`.env` 中 `OPENAI_API_KEY/OPENAI_BASE_URL/SERPER_SEARCH_API_KEY`。

#### Q5：如何向系统新增一个外部工具能力？
**标准回答**：
1) 若是 Python 工具：在 `genie-tool` 新增接口并由后端配置 `autobots` 指向对应的 URL；在 Java 侧实现一个 `BaseTool` 的子类包装请求与参数。
2) 若是 MCP 工具：将 MCP Server 的 SSE URL 加入 `mcp_server_url`；后端启动时通过 `McpTool.listTool` 动态发现并注入到 `ToolCollection`；LLM 侧将其暴露为 Function-Call 函数供模型选择。

#### Q6：项目中最容易出问题的链路是什么，如何排查？
**标准回答**：
- SSE 断流/代理缓存：检查前端请求头 `Accept: text/event-stream`、`Cache-Control: no-cache`，确认心跳是否稳定；后端 `SseEmitterUTF8` 是否设置 UTF-8。
- LLM 鉴权/配额：`application.yml` 中 Key/网关配置是否正确；工具 `.env` 中 `OPENAI_*` 是否可用。
- DeepSearch 失败：`SERPER_SEARCH_API_KEY` 是否配置。
- 端口冲突：检查 3000/8080/1601/8188 是否被占用。


