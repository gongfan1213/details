### 面试题：观测与治理

#### Q1：如何建立端到端的可观测性？
**标准回答**：
- 日志：前端关键事件（连接/断线/解析异常）、后端编排与工具调用入参摘要、LLM 请求参数与截断信息、SSE 心跳与关闭原因；日志统一打上 `requestId/sessionId`。
- 指标：SSE 存活时长、消息速率、丢包/解析失败率、LLM 成功率/延迟、工具调用时长分布、文件上传下载量；Prometheus+Grafana 统一汇总与告警。
- Trace：在后端与 Python 工具间透传 traceId，链路打通（OpenTelemetry）。

#### Q2：怎样定位一次“用户收不到增量”的问题？
**标准回答**：
1) 前端：Network 是否持续收到 `packageType !== 'heartbeat'` 的 data；解析 JSON 是否报错。
2) 后端：`queryAgentStreamIncr` 是否成功与 `/AutoAgent` 建立连接；是否只收到 `heartbeat`；是否有异常 stack。
3) 工具：是否持续产出；是否发送 `[DONE]`；心跳是否定时；网络是否被代理切断。

#### Q3：如何做灰度与开关治理？
**标准回答**：
- 配置中心/环境变量：切换 `llm.settings`、工具开关、MCP 服务列表；按租户/用户灰度不同模型与工具集。
- 观察指标变化（错误/延迟/成本）并自动回滚；对高风险工具加白名单与参数校验。

#### Q4：成本治理有哪些抓手？
**标准回答**：
- 输入控制：Token 截断、文件摘要与片段化、历史对话裁剪；提示词按场景模板化减少冗余。
- 输出控制：结果聚合而非散列重复；做“必要即返回”，减少无效中间体暴露；批量流式而非逐 token。
- 工具调用：防重复、失败快速失败；MCP 工具按并发窗口与配额控制。

#### Q5：安全与合规？
**标准回答**：
- 数据：敏感词检测、掩码；日志脱敏（Key/Token/个人信息）；跨域与鉴权策略。
- 执行：代码解释器白名单库、文件隔离目录与权限，限制网络访问；对外部 MCP 工具审计与配额。


