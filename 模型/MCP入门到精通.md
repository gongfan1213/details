根据 MCP 的相关文档表明，sampling 是 MCP 的一项强大功能，允许服务器通过客户端请求大型语言模型（LLM）进行内容补全，进而可实现复杂的代理行为，同时还能维持安全性与隐私性。  

其流程通常是服务器向客户端发送 `sampling/createMessage` 请求，客户端据此从 LLM 获取补全内容，再把结果返还给服务器。此过程采用 “人在回路中” 的设计理念，客户端能够向用户展示建议提示及补全结果，用户有权修改或拒绝它们，进而确保用户可管控 LLM 读取及生成的内容。

Sampling 可助力达成诸多代理模式，像是阅读与分析资源、依据上下文做决策、生成结构化数据、处置多步骤任务以及给予交互式协助等。 


### **1. 揭秘 Anthropic 的模型上下文协议 (MCP)：连接 AI 的新途径**

模型上下文协议 (Model Context Protocol, MCP) 是由 Anthropic 于 2024 年 11 月推出的一项开放标准。其核心目标是标准化人工智能 (AI) 模型（尤其是 Anthropic 的 Claude）与外部数据源和工具的连接方式。可以将 MCP 视为 AI 应用程序的“USB 端口”，提供了一个通用的接口，使得不同的 AI 模型能够以统一的方式与各种数据和服务进行交互。

```notion-code javascript
+-------+       +-----------+       +--------------+
| AI    |--->   | MCP       |--->   | External Data|
| Model |       | Interface |       | & Tools      |
+-------+       +-----------+       +--------------+
           (Like a USB Port for AI)
```

在传统的 AI 应用开发中，每当需要将 AI 模型与新的数据源或工具集成时，开发者往往需要编写特定的集成代码，这导致了架构的碎片化和难以扩展。MCP 的出现正是为了解决这个被称为“N×M 集成问题”的挑战，它为 AI 提供了一种与各种环境进行交互的统一方式。开发者不再需要为每个数据源编写重复的自定义集成代码，而是可以使用一套标准的协议进行连接。MCP 支持 AI 工具与各种数据源之间建立安全的双向连接。值得注意的是，一些早期采用者，如 Block 和 Apollo，已经开始在其系统内集成 MCP，而 Zed、Replit、Codeium 和 Sourcegraph 等开发工具公司也在积极利用 MCP 来增强其平台的功能。MCP 的发布时间（2024 年底）表明这是一项相对较新的技术，而早期采用者的出现预示着一个正在发展但充满潜力的生态系统。因此，理解 MCP 不仅需要掌握其基本原理，也需要关注其未来的发展方向。此外，“USB 端口”的比喻被广泛使用，这清晰地传达了 MCP 旨在实现标准化和互操作性的核心目标。理解并有效利用这个比喻将有助于把握 MCP 的本质。


### **2. 剖析架构：MCP 如何实现无缝通信**

MCP 遵循客户端-服务器架构模型，其核心包含三个关键组件：主机 (Host)、客户端 (Client) 和服务器 (Server)。

```notion-code javascript
+--------+    +--------+    +----------+
| Host   |--->| Client |--->| Server   |
|(e.g.,  |    |(Inside |    |(Provides |
|Claude) |    | Host)  |    | Data/    |
+--------+    +--------+    | Tools)   | 
                            +----------+
```

- **MCP 主机 (Host):** 通常是需要访问外部数据或工具的语言模型应用程序，例如 Claude Desktop 或集成了 AI 功能的集成开发环境 (IDE)，如 Cursor 。主机是发起连接并利用服务器能力的代理。

- **MCP 客户端 (Client):** 客户端是驻留在主机应用程序内部的连接器 。它与一个或多个服务器保持一对一的连接 ，负责与服务器进行通信，以利用其提供的功能 。客户端的首要任务是向服务器查询其提供的工具、资源或提示模板列表（能力发现）。当 AI 模型决定使用某个工具或资源时，客户端会接收到模型的请求，并在 MCP 服务器上执行相应的操作 。

- **MCP 服务器 (Server):** 服务器的主要职责是向客户端提供上下文信息、工具和预设的提示 。服务器通过 MCP 协议暴露特定的功能，并连接到本地或远程的数据源 。服务器内部实现了访问数据和执行操作的逻辑 ，并将结果返回给客户端 。目前已经存在许多不同用途的 MCP 服务器，例如用于文件系统操作 、数据库交互（支持 PostgreSQL 和 SQLite）、访问 Google Drive 、与 Slack  和 GitHub  等平台集成。

清晰理解主机、客户端和服务器之间的角色划分是掌握 MCP 架构的关键。每个组件都承担着特定的职责，共同协作以实现 AI 模型与外部世界的无缝连接。

**表 1: MCP 架构组件**

```csv
**组件**,**描述**,**示例**
主机 (Host),发起连接的 LLM 应用程序,"Claude Desktop, Cursor, AI 驱动的 IDE"
客户端 (Client),主机应用程序内管理与服务器连接的连接器,Claude Desktop 应用程序的一部分，IDE 的 MCP 插件
服务器 (Server),提供上下文、工具和提示；连接到数据源,文件系统服务器，数据库服务器，Slack 服务器，GitHub 服务器
```


### **3. 掌握核心要素：深入剖析 MCP 基础原语**

MCP 的强大功能建立在其定义的三种核心原语之上：资源 (Resources)、工具 (Tools) 和提示 (Prompts)。

```notion-code javascript
+-----------+     +---------+     +-----------+
| Resources |<--->| Tools   |<--->| Prompts   |
|(Data   )  |     |(Actions)|     |(Templates)|
+-----------+     +---------+     +-----------+
```

- **资源 (Resources):** 资源是 MCP 服务器向语言模型暴露数据的方式。它们类似于 REST API 中的 GET 请求，用于提供信息，而不应执行任何具有副作用的操作。资源可以是静态的，例如应用程序的配置信息，也可以是动态的，例如用户的个人资料数据。客户端通过统一资源标识符 (URI) 来访问这些资源。例如，一个文件系统服务器可以暴露读取本地文件的资源；一个数据库服务器可以提供访问数据库数据的资源；而一个 Google Drive 服务器则可以暴露检索存储在云盘中的内容的资源。将 MCP 资源比作 REST API 的 GET 请求有助于熟悉 Web 服务开发的开发者理解其概念。这种类比可以有效地弥合不同技术背景受众之间的理解鸿沟。

- **工具 (Tools):** 工具赋予语言模型通过 MCP 服务器执行操作的能力。它们类似于 REST API 中的 POST 请求，通常会执行计算并产生副作用。工具本质上是语言模型可以调用的可执行函数。每个工具都通过名称、参数（通常使用 Zod 等模式定义）以及一个回调函数来定义，当工具被调用时，该回调函数会执行相应的操作。例如，一个文件系统服务器可以提供写入文件的工具；一个 Slack 服务器可以提供发送 Slack 消息的工具；一个数据库服务器可以提供执行数据库查询的工具；而一个 Puppeteer 服务器可以提供自动化浏览器操作的工具。AI 模型通过工具触发操作的能力是 MCP 的一个强大特性，它使得 AI 能够与现实世界的系统进行交互并实现自动化。通过展示实际应用场景，例如 AI 助手自动发送邮件或更新数据库，可以更好地理解工具的潜力。

- **提示 (Prompts):** 提示是用于指导语言模型与服务器进行交互的可重用模板。它们帮助语言模型有效地与服务器进行交互，并定义了交互的模式。提示可以包含指令或指令模板。当用户提出查询时，AI 模型会分析查询内容以及可用的 MCP 工具和资源，然后决定是否需要使用某个工具或资源（增强提示）。MCP 中的提示不仅仅是简单的用户输入，它们提供了结构和上下文，指导 AI 有效地利用可用的工具和资源。精心设计的提示对于成功的 MCP 交互至关重要，因为它们能够帮助 AI 理解用户的意图并选择最合适的工具或资源来完成任务。


### **4. 开启您的 MCP 之旅：初学者实用指南**

要开始使用 Anthropic 的模型上下文协议 (MCP)，首先需要搭建开发环境并安装必要的软件开发工具包 (SDK)。

- **设置开发环境并安装必要的 SDK:** MCP 提供了多种编程语言的 SDK，包括 TypeScript、Python、Java 和 Kotlin。具体的安装说明可以在官方文档中找到。对于 TypeScript，通常使用`npm` 包管理器；对于 Python，则可以使用`pip` 或`uv` 包管理器。这些 SDK 的存在大大降低了开发者使用 MCP 的门槛，使得他们可以使用自己熟悉的编程语言进行开发。报告应该强调这一点，并为读者提供清晰的 SDK 获取和安装指南。

- **使用客户端应用程序（例如 Claude Desktop）连接到现有的 MCP 服务器:** Anthropic 的 Claude Desktop 应用程序内置了对 MCP 服务器的支持。要配置 Claude Desktop 以使用 MCP 服务器，通常需要编辑配置文件（例如`claude_desktop_config.json` ）。在配置文件中，需要指定运行 MCP 服务器的`command` 和`args` 。Claude Desktop 应用还支持本地 MCP 服务器。除了 Claude Desktop，其他一些客户端应用程序，如 Cursor，也支持 MCP，允许用户连接到外部系统和数据源。对于初学者来说，从 Claude Desktop 开始是一个简单易行的方法，无需编写代码即可体验 MCP 的功能。报告应该详细指导用户完成在 Claude Desktop 中配置 MCP 服务器的步骤。

以下是一个配置 Claude Desktop 以连接到名为 “weather” 的 Python MCP 服务器的示例配置（`~/Library/Application Support/Claude/claude_desktop_config.json` ）：

```notion-code javascript
{
  "mcpServers": {
    "weather": {
      "command": "uv",
      "args":
    }
  }
}
```

请将`/ABSOLUTE/PATH/TO/PARENT/FOLDER/weather` 替换为您的实际服务器文件路径 .

- **运行您的首次 MCP 交互：分步示例:** 为了帮助初学者更好地理解 MCP 的工作方式，可以提供一个简单的交互示例。例如，可以使用 Memory Server 来存储和检索信息。首先，需要在 Claude Desktop 的配置文件中添加 Memory Server 的配置。然后，可以在与 Claude 的对话中使用 Memory Server 来添加知识并进行检索。另一个例子是使用官方快速入门中的天气服务器示例 。通过提供具体的操作步骤和示例对话，可以帮助用户快速上手并体验 MCP 的基本功能。这个简单的交互示例将有助于巩固读者对 MCP 概念的理解，并为他们提供一个可以实践的起点。

例如，在配置了 Memory Server 后，您可以与 Claude 进行如下对话:

> 
> 
> 用户: 我想记住我的猫的名字是 Luna。
> 
> 
> 
> **Claude:** 好的，我已经将你的猫的名字 Luna 存储起来了。
> 
> 
> 
> **用户:** 我的猫叫什么名字？
> 
> 
> 
> **Claude:** 你的知识库中显示你的猫的名字是 Luna。
> 
>


### **5. 打造您的 MCP 强大功能：构建自定义服务器**

当您对 MCP 的基本概念和使用方法有了一定的了解后，就可以开始构建自己的自定义 MCP 服务器，以满足特定的需求。

- **设计自定义服务器的功能:** 在开始构建之前，需要明确您的自定义服务器需要提供的具体功能。这包括确定您希望向 AI 模型暴露哪些特定的数据或工具，以及这些数据或工具应该如何通过资源、工具和提示来呈现。此外，还需要仔细考虑服务器的安全性，包括如何进行身份验证和授权，以及如何控制对敏感数据的访问。

- **利用 MCP SDK 实现资源和工具:** MCP SDK 提供了创建资源和工具所需的 API。无论是使用 TypeScript 还是 Python SDK，都需要编写代码来定义资源的 URI、工具的参数和回调函数。对于 TypeScript，可以使用 Zod 等库来定义参数的模式；对于 Python，则可以使用类型提示。在工具的回调函数中，需要实现与外部系统或数据进行交互的逻辑。同样，也需要编写代码来定义如何通过资源提供数据。为了帮助开发者更好地理解如何构建自定义 MCP 服务器，报告应该包含清晰且带有注释的代码示例，至少使用一种流行的编程语言（最好是 TypeScript 和 Python）。

**TypeScript 示例:**

以下是一个使用 TypeScript SDK 创建一个简单的 MCP 服务器的示例，该服务器暴露了一个名为`calculate_sum` 的工具，用于计算两个数字的和:

**TypeScript**

```notion-code javascript
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";

const server = new Server({
  name: "simple-calculator-server",
  version: "0.1.0",
});

server.tool(
  "calculate_sum",
  {
    a: z.number(),
    b: z.number(),
  },
  async ({ a, b }) => {
    return {
      toolResult: a + b,
    };
  }
);

const transport = new StdioServerTransport();
await server.connect(transport);
```

**Python 示例:**

以下是一个使用 Python SDK (FastMCP) 创建一个类似的 MCP 服务器的示例:

**Python**

```notion-code javascript
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("simple-calculator-server")

@mcp.tool()
def calculate_sum(a: int, b: int) -> int:
    """Add two numbers"""
    return a + b

if __name__ == "__main__":
    mcp.run(transport='stdio')
```

这些示例展示了如何使用各自的 SDK 定义一个简单的工具。更复杂的服务器可能包含多个工具、资源和提示。

- **处理身份验证和授权以实现安全访问:** 安全性是 MCP 服务器开发中至关重要的一环。需要实施适当的身份验证机制（例如，API 密钥、OAuth）来验证客户端的身份，并使用授权策略来控制客户端对特定资源或工具的访问权限。在 MCP 服务器的实现中，需要加入相应的身份验证和授权检查逻辑，以确保只有经过授权的客户端才能访问受保护的功能。此外，还需要强调用户对其数据访问的明确同意和控制权，并遵循“本地优先”的原则，对每次工具的使用和数据交互都需要显式的权限。鉴于 MCP 允许 AI 访问和操作潜在的敏感数据和系统，安全性是至关重要的。报告必须详细讨论安全注意事项，并提供关于在自定义 MCP 服务器中实现身份验证和授权的指导。


### **6. 使用 MCP 释放 Claude 的潜力：真实世界集成场景**

Anthropic 的模型上下文协议 (MCP) 为 Claude 提供了与各种外部系统和数据源进行交互的能力，从而极大地扩展了其应用场景。

- **将 Claude 与本地文件系统集成以增强上下文:** 通过为本地文件系统创建一个 MCP 服务器，可以使 Claude 能够读取和写入本地文件 。这种集成可以应用于多种场景，例如总结本地文档、根据项目文件生成代码或组织管理本地文件。例如，可以使用`@modelcontextprotocol/server-filesystem` 这个预构建的服务器 。然而，在授予 AI 模型文件系统访问权限时，务必考虑到潜在的安全风险并采取相应的安全措施。将 Claude 连接到本地文件系统可以解锁强大的个人生产力和开发工作流程。报告应该通过实际案例来说明这些可能性，例如 Claude 如何帮助用户快速找到某个文件中的信息或根据用户的指令修改文档。

- **通过 MCP 将 Claude 连接到外部 API 和服务:** 可以创建 MCP 服务器来集成各种流行的外部应用程序编程接口 (API)，例如天气服务 、知识库或生产力工具。通过这些集成，Claude 可以获取最新的信息，提供更相关的答案，或者在外部平台上执行操作。例如，可以使用预构建的服务器连接到 Google Drive、Slack 和 GitHub 等服务。Claude 还可以通过 MCP 服务器与 AI2SQL 集成，从而可以使用自然语言查询数据库。将 Claude 与外部 API 集成可以使其能力超越其训练数据，使其能够与实时世界互动并访问专业化的信息。报告应该展示 MCP 在实现此类集成方面的多功能性，例如展示如何使用 MCP 连接到股票数据 API 或翻译服务 API。

- **使用 Claude 和自定义 MCP 服务器自动化任务和工作流程:** 借助自定义的 MCP 服务器，Claude 可以自动化重复性的任务或复杂的工作流程。例如，可以创建一个 MCP 服务器来自动生成报告、触发持续集成/持续部署 (CI/CD) 流程，甚至控制智能家居设备。例如，一个名为 "MCP Tasks Organizer" 的服务器可以将 Cursor agent 的计划转换为结构化的 Markdown 任务列表并将其组织到代码仓库中 。通过 MCP 将 AI 与工具和服务连接，为自动化开启了广阔的前景，可以显著提高效率和生产力。报告应该探讨这些可能性，并鼓励用户创造性地思考如何利用 MCP 进行自动化。例如，可以设想一个场景，Claude 能够根据会议纪要自动创建任务并分配给团队成员。


### **7. 探索 MCP 的高级功能：超越基础**

Anthropic 的模型上下文协议 (MCP) 除了提供基本的连接功能外，还支持一些高级特性，以满足更复杂的需求。

- **理解不同的 MCP 传输协议 (stdio, SSE):** MCP 支持多种传输协议，其中两种主要的协议是标准输入/输出 (stdio) 和服务器发送事件 (Server-Sent Events, SSE)。stdio 传输协议通过命令行进行客户端和服务器之间的通信。而 SSE 传输协议则基于 HTTP 进行通信。每种传输协议在不同的场景下都有其优缺点。例如，stdio 适用于本地进程间的通信，而 SSE 更适合于需要实时数据推送的场景。理解这些不同的传输协议，可以帮助开发者为他们的特定用例和部署环境选择最合适的方案。报告应该对 stdio 和 SSE 进行清晰的比较，并说明它们各自的适用场景。

- **实现复杂的工具链和多步骤交互:** MCP 允许将多个工具连接在一起，形成工具链，以完成更复杂的任务。在一个多

步骤的交互中，AI 模型可以将一个工具的输出作为另一个工具的输入，从而实现更高级的功能。这需要仔细地设计工具之间的依赖关系和数据流，并进行有效的编排和规划。例如，一个工具可能负责从数据库中检索数据，另一个工具则负责对数据进行分析，最后再由一个工具将分析结果可视化。构建工具链的能力使得 AI 模型能够执行更复杂的工作流程，从而解决更广泛的问题。报告应该通过示例来说明如何设计和实现这样的工具链。

- **利用 MCP 实现代理工作流程和自主 AI 系统:** MCP 可以作为构建更高级的 AI 代理的基础，这些代理能够自主地与外部系统进行交互，以实现用户的目标。MCP 提供了代理所需的上下文信息和工具，使其能够根据用户的指令进行规划、决策和执行。MCP 规范中提到的“采样”概念也与服务器发起的代理行为和递归的语言模型交互有关。例如，一个旅行规划代理可以使用 MCP 连接到日历、航班预订和酒店预订服务，自主地为用户规划行程。MCP 在构建更自主、能够与其环境无缝交互的 AI 代理方面具有巨大的潜力。报告应该简要介绍 MCP 在 AI 代理领域的应用前景。


### **8. 确保使用 MCP 进行安全和负责任的 AI 交互**

在使用 Anthropic 的模型上下文协议 (MCP) 构建 AI 应用程序时，确保安全性和负责任的交互至关重要。

- **管理用户同意和权限的最佳实践:** 对于 AI 模型通过 MCP 访问数据和执行工具，必须获得用户的明确同意。在用户界面设计中，应该清晰地告知用户 AI 模型正在请求哪些权限，并提供易于理解的方式来授予或拒绝这些权限。同时，还需要提供管理和撤销已授予权限的机制。Cursor 中的“Yolo Mode”是一个可以绕过批准提示的例子，但也存在潜在的风险。因此，实施有效的同意管理机制对于建立用户对 AI 应用程序的信任至关重要。报告应该提供关于如何实施有效的同意管理机制的实用建议。

- **保护通过 MCP 访问的敏感数据的策略:** 在处理通过 MCP 访问的敏感数据时，需要采取严格的安全措施。这包括安全地存储和传输 API 密钥以及其他敏感凭证。同时，还需要使用数据清理和验证技术来防止潜在的安全漏洞。在 MCP 服务器的实现过程中，务必遵循安全最佳实践。例如，对于用户输入的数据，应该进行充分的验证，以防止注入攻击。报告应该强调处理 MCP 应用程序中敏感信息相关的风险，并提供相应的缓解策略。

- **负责任地部署使用 MCP 的 AI 应用程序的注意事项:** 负责任的 AI 部署不仅限于安全性，还包括伦理方面的考虑以及确保技术以有益于社会的方式使用。在使用 MCP 构建 AI 应用程序时，需要仔细考虑 AI 对数据的访问和操作可能带来的伦理影响。建议对 MCP 集成进行全面的测试和评估，以确保其行为符合预期，并且不会产生意想不到的后果。此外，还需要提高 AI 模型如何使用 MCP 与外部系统进行交互的透明度。例如，当 AI 模型执行某个操作时，应该向用户提供清晰的解释。报告应该简要讨论这些更广泛的责任问题。


### **9. MCP 的扩展领域：社区与未来方向**

Anthropic 的模型上下文协议 (MCP) 正在不断发展壮大，其社区也在日益活跃。

- **探索不断增长的预构建 MCP 服务器生态系统:** 在 GitHub 上有一个开放源代码的 MCP 服务器存储库 ，其中包含了大量预构建的服务器，可以用于连接各种流行的系统，例如 Google Drive、Slack、GitHub、Git、Postgres 和 Puppeteer 等 。此外，还有许多由社区开发者贡献的服务器以及来自各个公司的官方集成。用户还可以参考 Awesome MCP Servers 列表来发现更多可用的服务器。这些预构建的服务器极大地简化了开发者将 AI 与现有工具和服务集成的过程，无需从头开始构建所有内容。报告应该鼓励用户积极探索这些现有的资源。

- **为开源 MCP 社区做出贡献:** 开发者可以通过多种方式为 MCP 项目做出贡献，包括参与协议规范的制定、开发和完善 SDK，以及贡献新的服务器实现 。相关的 GitHub 存储库是进行贡献的主要场所 。作为一个开源项目，MCP 的发展离不开社区的积极参与。鼓励用户参与到 MCP 的开发中，将有助于推动协议的普及和演进。报告应该说明用户如何参与其中。

- **预测未来的发展和 MCP 标准的演变:** 作为一项相对较新的技术，MCP 很可能会随着人工智能和集成技术的不断发展而演变。未来可能会出现新的功能和改进，例如对现有 SDK 的增强支持或新的 SDK 的发布。MCP 的发展潜力巨大，有望对更广泛的 AI 领域产生深远的影响。报告应该对 MCP 的潜在未来发展方向进行展望，帮助用户了解该协议的长期愿景。


### **结论**

Anthropic 的模型上下文协议 (MCP) 代表了 AI 集成领域的一个重要进步。通过提供一个开放、标准化的框架，MCP 解决了传统 AI 集成中存在的复杂性和碎片化问题。从初学者到专家，理解和掌握 MCP 对于构建下一代互联 AI 应用程序至关重要。其客户端-服务器架构、核心原语以及不断壮大的生态系统为开发者提供了强大的工具，可以轻松地将 AI 模型与各种外部数据源和工具集成。随着 MCP 社区的持续发展和技术的不断成熟，它有望在未来的 AI 领域发挥越来越重要的作用。
