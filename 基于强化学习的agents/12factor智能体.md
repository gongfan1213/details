https://www.youtube.com/watch?v=8kMaTybvDUw


<img width="744" height="426" alt="image" src="https://github.com/user-attachments/assets/0c0a8a22-a3a6-499b-9c79-adf3663cbb95" />


<img width="699" height="380" alt="image" src="https://github.com/user-attachments/assets/635fbd48-8267-4966-9007-1fdd1ba9d6d5" />

unify execution state and business state

launch /pause/resume with simple apis

execution state:

current step

next step

waiting status

retry config

etc

bustiness state: whats happend in the agent workflow so far

list of openai messages

list of tool calls and results etc

launch prase,resume




该内容围绕构建可靠AI智能体展开，结合实践经验总结了核心思路、关键要素及实践原则，以下是详细总结：


### 一、构建智能体的常见误区与前期认知
1. **“智能体万能论”的破除**  
   并非所有问题都适合用智能体解决。例如演讲者尝试的DevOps智能体，最终发现用bash脚本90秒就能完成的任务，无需复杂智能体。需先判断问题是否真正需要智能体——若可通过简单脚本或确定性逻辑解决，无需强行使用智能体。

2. **“快速达标即终点”的认知纠正**  
   智能体易快速达到70%-80%的效果，但突破这一阈值需深入底层逻辑（如提示词构建、工具调用流程），而非依赖现有框架“黑箱操作”。若仅停留在表面，会陷入“难以优化”的困境，甚至需彻底重构。


### 二、构建可靠智能体的核心原则（12要素核心思路）
#### 1. 从软件工程本质出发：智能体即“特殊软件”
   - 智能体的核心是“LLM输出+确定性代码”的结合：LLM的作用本质是将自然语言转换为结构化数据（如JSON），再由传统代码（循环、switch语句等）处理，而非“神秘的自主实体”。工具调用、流程控制等均可拆解为“JSON交互+代码逻辑”，无需被“智能体”概念复杂化。
   - 借鉴成熟软件工程实践：如用有向无环图（DAG）拆分任务、掌控控制流（类似Airflow等编排工具）、管理状态（执行状态+业务状态），实现智能体的启动、暂停、恢复等标准化操作。

#### 2. 掌控核心环节：提示词与上下文窗口
   - **提示词的“精细化掌控”**：  
     优质提示词是智能体可靠性的基础。框架可提供基础模板，但最终需手动优化每个token——LLM是“输入决定输出”的纯函数，需通过反复测试、调整提示词细节（如指令清晰度、信息密度）提升效果，而非依赖框架默认配置。
   - **上下文窗口的“可控性”**：  
     避免盲目堆砌信息（如超长对话历史、完整错误堆栈），需主动筛选、总结关键内容。例如：工具调用出错时，仅传入精简的错误摘要而非全量日志；根据任务目标定制上下文格式（如用户消息+系统指令组合），提升信息传递效率。

#### 3. 优化控制流：拒绝“黑箱循环”，拥抱“可控逻辑”
   - **打破“LLM自主决策到底”的模式**：  
     纯依赖LLM自主决定下一步（如“循环调用工具直到完成”）在长流程中不可靠（易丢失上下文、重复操作）。需人工介入控制流：设定最大步骤数、关键节点强制校验（如人类审批）、错误时主动重置上下文。
   - **用“微型智能体”拆分复杂任务**：  
     大型智能体易失控，建议拆分为多个“小型专注智能体”，每个负责3-10步明确任务（如部署流程中，拆分为“前端部署智能体”“后端部署智能体”），通过确定性代码串联，既保留灵活性又降低复杂度。

#### 4. 人机协作：智能体的“可靠性补充”
   - 在关键节点引入人类决策：例如部署流程中，让智能体生成操作建议，由人类确认后再执行；遇到模糊需求时（如用户指令不明确），智能体主动请求澄清，而非盲目执行。
   - 适配人类使用场景：支持邮件、Slack、短信等多种交互渠道，避免要求用户使用特定“智能体界面”，提升实用性。

#### 5. 警惕“过度依赖框架”，保留灵活性
   - 框架的作用是“简化基础工作”，而非“替代核心设计”：例如框架可处理状态存储、API调用等重复工作，但提示词设计、控制流逻辑等核心环节需自主掌控，避免被框架绑定导致无法优化。
   - 优先“可拆解、可调试”的设计：智能体应具备清晰的模块边界（如提示词生成、工具调用、状态管理分离），便于定位问题（如某次错误是提示词缺陷还是工具逻辑错误）。


### 三、实践建议：从“能运行”到“高可靠”的进阶路径
1. **从“边界任务”切入**：选择LLM“刚好能完成但不稳定”的任务（如需要一定推理但规则明确的场景），通过工程化设计（如上下文优化、人工校验）提升可靠性，而非挑战超出当前能力的复杂任务。
2. **重视“失败案例”的迭代**：记录智能体出错的场景（如工具调用错误、上下文丢失），针对性优化（如错误信息精简传入、控制流中增加重试校验），而非依赖模型升级被动解决。
3. **保持“轻量与聚焦”**：智能体应“小而专”，避免功能堆砌。例如部署相关智能体仅负责“部署步骤决策”，其他环节（如测试、回滚）由专用模块或确定性代码处理，降低失控风险。


### 四、核心结论
智能体的可靠性并非依赖“LLM的智能”，而是“软件工程的严谨性”——通过拆解任务、掌控核心环节（提示词、上下文、控制流）、结合人机协作，将“模糊的智能体逻辑”转化为“可控的软件系统”。框架是工具，最终需以“可理解、可优化、可适配”为目标，从实际需求出发设计智能体。



现场有谁在构建智能体？
如果已经构建了10个以上智能体的，请举手。有人构建过100个以上吗？
好的，有几位，很棒，非常好。
我想我们很多人都在构建智能体的道路上。对我来说，事情是这样的：我决定要构建一个智能体，我们想清楚了要让它做什么。我们想快速推进，作为开发者，我们会使用库，不会从零开始编写所有东西。然后你能让它达到70%到80%的效果，这足以让CEO感到兴奋，还能给你的团队再增加6个人。但之后你会意识到，70%到80%的效果还不够好，而且如果你想突破这个质量门槛，你就得深入到调用栈的第七层，去逆向工程弄明白这个提示是怎么构建的、这些工具是怎么传入的、这一切都来自哪里。如果你和我一样，最终你会把这些都抛弃，从头开始。或者你甚至会发现，这根本不是一个适合用智能体解决的问题。我记得我尝试构建的第一个智能体是一个DevOps智能体，我当时想：“这是我的make文件，你可以运行make命令来构建项目。”但它搞不清楚步骤，把所有事情都弄反了。我想：“好吧，那我来优化提示词。”在接下来的两个小时里，我把每一个细节、每一个步骤都讲得越来越详细，直到最后我把构建步骤的准确顺序都列出来了。这是个有趣的尝试，但最后我意识到，我本可以用90秒写一个bash脚本来做这件事。不是所有问题都需要智能体来解决。

我一直在这条路上探索，我想你们很多人也有类似的经历。在努力帮助人们构建更好、更可靠的智能体的过程中，我和100多位创始人、开发者、工程师交流过，然后我开始发现一些模式。其一，大多数生产环境中的智能体其实根本没那么“智能体化”，它们大多只是普通软件，但有一些核心的做法，很多人都在采用这些模式，让他们基于大语言模型（LLM）的应用变得非常出色。他们都没有进行全新的重写，而是采用了这些没有名字、没有定义的小型模块化概念，并把它们应用到现有的代码中。真正酷的是，我认为你不需要有AI背景就能做到这一点。这是软件工程的基本知识——或许不是最基础的那种，但就像Heroku需要定义构建云应用的方式一样，十年前我们甚至都不会称它们为云原生，但那就是构建能在云端运行的应用的方法。基于在这个领域看到的一切，我决定整理出我认为的AI智能体的12个要素。我们建立了这个GitHub仓库，你可以去看看。事实证明，很多其他人也有相同的感受和看法。我们一整天都在Hacker News的首页，在社交平台上有20万的浏览量。我就把这个放出来，不多做评论。

说一下背景，我们在一两个月内就获得了大约4000个星标，有14位活跃的贡献者。很容易就能读懂这个仓库的内容，听完这个演讲后会觉得，这是一场反框架的演讲。但我不是来抨击框架的，我更愿意把这看作一个愿望清单，一份功能需求清单——我们如何才能让框架满足那些优秀开发者的需求，他们需要极高的可靠性，同时又希望能快速推进工作。

我来这里是为了什么呢？我希望你们能暂时忘记关于智能体的一切，从最基本的原理重新思考，如何把我们从软件工程中学到的所有知识，应用到构建真正可靠的智能体的实践中。我们会稍微调整一下顺序，如果你想按顺序了解所有12个要素，那得讲30分钟，所以我们会把一些内容合并起来讲。最后会有一个二维码，你可以随时去深入了解。

第一个要素：大语言模型（LLMs）能做的最神奇的事情，和循环、switch语句、代码、工具之类的都没关系，而是能把这样一句话转换成这样的JSON。你用这个JSON做什么都不重要——其他要素会涉及这一点，但只要你在做这件事，你今天就能把这部分内容融入你的应用中。

第四个要素：这就引出了一个话题。有人读过这篇论文吗？《Go To语句considered harmful》，或者只是听说过？我其实从没真正读过，但它讲的是在C编程语言以及当时其他一些编程语言中，有个叫“go to”的抽象概念，大家觉得它会把代码搞得很糟糕，是一种错误的抽象，谁都不应该用。我斗胆说一句，“工具使用”是有害的——我加了引号，因为我不是说让智能体接触外部世界是有害的，显然那非常厉害。但我认为让事情变得困难的是，把工具使用当成了一种神奇的事情，好像有个神秘的外来实体在和环境交互。但实际上，我们的大语言模型输出JSON，我们把它交给一些确定性的代码去执行某些操作，然后可能再把结果反馈回去——不过这又是其他要素的内容了。所以如果你有这样的结构，并且能让大语言模型输出生成这些结构的内容，你就可以把它传入这样的循环或者这样的switch语句中。工具没什么特别的，它只是JSON和代码而已——这就是第四个要素。

第八个要素：我们把几个要素合并在一起讲。掌控你的控制流。我想退一步讲讲我们是怎么走到这一步的。我们在软件中编写有向无环图（DAGs）已经有很长时间了，如果你写过if语句，你就已经写过有向图了——代码本身就是一种图。你可能也熟悉DAG编排工具，有人用过像Airflow或者Prefect之类的工具吗？把事情分解成节点的这种概念，能给你一定的可靠性保障。但智能体本应做到的——我想很多人都在谈论这一点，在某些情况下也确实实现了——是你不必编写这个有向无环图，你只需要告诉大语言模型目标是什么，它就会找到实现目标的路径。我们把这建模成一个非常简单的循环：大语言模型决定下一步，你构建一些上下文窗口，直到大语言模型说“好了，我们完成了”。

在实际中，情况大概是这样的：有一个事件进来，你把它传入你的提示词，模型说要调用一个API，你得到结果，把结果放到上下文窗口里，再把整个窗口传回提示词。这是构建智能体最基础、最简单的方式。大语言模型会调用几个步骤，最后它会说，好了，我们已经完成了初始事件带来的所有任务——初始事件可能是用户让它做某事的消息，也可能是一个故障。然后我们得到最终答案，我们的实例化有向无环图就是这三个步骤按顺序排列。

事实证明，这其实不太管用，尤其是在处理更长的工作流时。主要是因为上下文窗口太长了，当然还有其他一些原因。有人试过把两百万个标记输入Gemini，看看会发生什么吗？你可以这么做，你会得到一个答案，API会返回一些东西，但我想没人会说，你把越多标记放进上下文窗口，就总能得到越严谨、越好、可靠性越高的结果。

所以这方法不太奏效，但我们会以此为抽象基础继续构建。智能体到底是什么呢？你有提示词，它给出关于如何选择下一步的指令；你有switch语句，它接收模型输出的JSON并进行相应处理；你有构建上下文窗口的方法；还有一个决定何时、何地、如何以及为何退出的循环。如果你掌控了控制流，你就能做一些有趣的事情，比如break和switch、总结、让大语言模型做判断等等。

这就引出了我们如何管理智能体的执行状态和业务状态。很多工具会给你诸如当前步骤、下一步、重试次数之类的东西——所有的有向无环图编排工具都有这类概念。但你也有你的业务状态：发生过哪些消息、我们要向用户展示哪些数据、我们在等待哪些审批等等。我们希望能像操作任何标准API一样，启动、暂停、恢复这些状态。这一切都只是软件而已。所以如果你能把你的智能体放在REST API或者MCP服务器后面，并以这样的方式管理循环：正常请求进来，我们把上下文窗口加载到大语言模型中；我们要允许智能体调用长期运行的工具，这样我们就能中断工作流，把上下文窗口直接序列化到数据库中——因为我们掌控着上下文窗口，这一点我们后面会讲到；然后当我们启动工作流时，它最终会带着状态ID和结果回调，我们用状态ID把状态从数据库中加载回来，然后把结果附加到程序中，再传回大语言模型。智能体甚至不会知道后台发生了这些事情。

智能体只是软件，所以构建优秀的智能体需要很大的灵活性，你真的需要掌控所有这些内容组合在一起的内部循环——这就是统一、暂停和恢复。

第二个要素：我想大多数人首先会发现的一点是，你真的需要掌控你的提示词。有一些很好的提取方法，如果你不想花太多时间手写提示词，你可以把一些内容放进去，就能得到一套很好的基本要素，还有一个非常好的提示词——这样的提示词可能要去“提示词学校”学三个月才能写出来。但最终，如果你想突破某个质量门槛，你就得亲手写下每一个标记。因为大语言模型是纯粹的聚焦函数，决定你的智能体可靠性的唯一因素是你能输出什么样的标记，而决定你输出标记的唯一因素——除了重新训练你自己的模型之类的——就是仔细斟酌你输入的标记。

我不知道哪种方法更好，也不知道你想如何构建你的提示词，但我知道你尝试的方法越多、测试的调节项越多、评估的内容越多，你就越有可能找到非常好的方法。掌控你的提示词，你还需要掌控构建上下文窗口的方式。你可以使用标准的OpenAI消息格式，或者在让大语言模型选择下一步的时候，你唯一要做的就是告诉它到目前为止发生了什么。你可以用任何你喜欢的方式，把所有信息放进一个用户消息里，问“接下来会发生什么”，或者放进系统消息里。你可以用任何你喜欢的方式建模你的事件状态、线程模型，用任何你喜欢的方式把它们序列化为字符串。我们在内部构建的一些智能体中使用的一些跟踪信息——我稍后会讲到——可能看起来是这样的。但如果你不查看每一个标记，不优化你向大语言模型传递信息的密度和清晰度，你可能就会错过提升质量的机会。

大语言模型是纯函数：标记进，标记出。让智能体变好的所有关键都在于上下文工程。你有你的提示词、你的记忆、你的检索增强生成（RAG）、你的历史记录——这一切都只是关于如何把正确的标记输入模型，让它给我们一个非常好的答案，解决用户的问题——主要是解决我的问题。我不知道哪种方法更好，但我知道你应该尝试所有方法。所以要掌控你的上下文构建。

这一点有点争议，所以它是一个独立的要素，要让它发挥作用，需要和其他要素结合起来。但当模型出错，比如错误地调用了API，或者调用了一个已停用的API时，你可以提取它的工具调用，获取相关的错误信息，把错误放到上下文窗口里，让它再试一次。有人遇到过这种糟糕的情况吗？看到模型陷入循环、变得混乱、失去上下文、卡住不动。这就是为什么你需要掌控你的上下文窗口。不要盲目地把东西都放进去。如果出现错误，然后你得到了一个有效的工具调用，要清除所有未处理的错误，对它们进行总结，不要把整个堆栈跟踪都放进你的上下文里，想清楚你要告诉模型什么，这样才能得到更好的结果。

用工具联系人类：这一点有点微妙，但我发现在实际中，几乎所有人都在输出的最开始就回避这个非常重要的选择——在工具调用和给人类的消息之间做选择。如果你能把重点放在自然语言标记上，你一方面可以给模型提供不同的表达方式，比如“我完成了”“我需要澄清”“我需要和经理谈谈”之类的；另一方面，你把第一个标记生成和采样的意图转移到了模型能理解的自然语言上。所以如果在这里引入人类输入，你的跟踪信息可能会是这样的。这能让你构建自动外循环智能体——我就不细讲了，如果你去我们的网站，有一个我写的相关帖子的链接，里面有很多内容。我不知道哪种方法更好，但你或许应该尝试所有方法。

用工具联系人类，这和“从任何地方触发事物”以及“在用户所在之处与他们相遇”是相辅相成的。人们不想打开七个不同的ChatGPT风格智能体标签页，就让人们通过电子邮件、Slack、Discord、短信之类的和你构建的智能体交流吧。我们看到这种方式在各地都流行起来了。

你应该构建小型、专注的智能体。我们已经讨论过那种结构为什么不起作用，那什么才起作用呢？人们实际采用的、效果非常好的是微型智能体。你仍然有一个基本确定的有向无环图，还有这些非常小的智能体循环，只有3到10个步骤。我们在Human Layer就是这么做的，我们有一个管理部署的机器人，我们的大部分部署流程是确定的CI/CD代码。但当我们到了GitHub PR已合并、开发环境测试通过这一步——抱歉——我们会把它发送给模型，说“把这个部署好”。模型说“好的，我要部署前端”，然后你可以把这个消息发给人类，人类说“实际上不行，先部署后端”。这就是把自然语言转换成工作流下一步的JSON。后端部署被提出、获批、执行，然后智能体知道，它必须在这一切完成后回去部署前端。所有步骤都完成且成功后，我们就回到确定性代码中，然后我们会在生产环境运行端到端测试，如果测试完成，否则我们就把它交给一个内部非常相似的回滚智能体。我就不深入讲了，但这是它在我们Slack频道里运行的样子。100个工具，20个步骤，很简单，上下文可控，职责明确。

很多人说：“如果大语言模型变得更智能呢？如果我能输入两百万个标记，它能处理呢？”我觉得我们很可能会看到这样的情况：你从一个基本确定的工作流开始，然后逐渐把大语言模型融入你的代码、后端、逻辑中。随着时间的推移，大语言模型能够处理更大、更复杂的任务，直到整个API端点、管道或者其他什么东西都由一个智能体来运行——这很棒。但你仍然需要知道如何设计这些东西以获得最佳质量。这是Notebook LM的人提出的，我认为他们说得很好：找到一个刚好在模型能可靠处理的边界上的任务——就是那种它不能一直做对的任务，如果你能想办法通过在系统中设计可靠性来让它始终做对，那么你就创造了神奇的东西，创造了比其他人更好的东西。

这就是小型、专注的智能体。有个关于无状态归约器的梗，有人在推特上告诉我，这不是归约器，而是转换器，因为有多个步骤。但本质上，智能体应该是无状态的，你应该掌控状态，用任何你喜欢的方式管理它。

我们都还在寻找正确的抽象概念。论文里我链接了几篇博客文章。框架与库——Ruby社区有一篇很旧的文章，讨论我们是想要重复还是想要弄清楚这些抽象概念。如果你想构建一个符合12要素的智能体，我们正在做一个叫“create 12-factor agent”的项目，因为我认为智能体需要的不是引导程序，你不需要一个内部东西的包装器，你需要更像Shad CN的东西——就是那种能搭建好框架，然后你能掌控它、掌控代码的东西，我觉得这样很好。

总结一下：智能体就是软件。你们都会构建软件。有人写过switch语句吗？while循环呢？好的，那我们就能做这些事。大语言模型是无状态函数，这意味着只要你在上下文中放入正确的内容，你就会得到最好的结果。掌控你的状态和控制流，去实践、去理解，因为这会给你灵活性。然后找到前沿领域，通过精心设计输入模型的内容和控制输出的方式，找到比其他人做得更好的方法。而且我认为，智能体有人类参与会更好，想办法让智能体与人类协作。构建智能体有很多困难的事情，但无论如何你都应该去做，至少现在是这样，而且大部分你都应该去尝试。我觉得很多框架试图去掉问题中困难的AI部分，这样你就能直接用了，但我认为应该反过来。我们得到的工具应该去掉其他困难的部分，这样我们就能把所有时间都花在困难的AI部分上——把提示词弄对、把流程弄对、把标记弄对。

我来这里是因为我经营着一家小企业，我们有一个初创公司，我们试图帮助大家做我们正在做的事情，我们在开源社区做这些事，我认为这非常重要，我们需要一起努力。还有一些困难的事情，但它们不那么重要，也不那么有趣，这就是我们在Human Layer要解决的问题。我们在做一个叫A2协议的东西，如果你想聊这个，可以来找我，这是一种整合智能体与人类联系方式的方法。但最重要的是，我喜欢自动化的东西，我在内部为自己构建了无数的智能体，用于找公寓，以及我们在Human Layer做的各种内部业务。

谢谢大家的观看，让我们一起去构建点什么吧。我在走廊等你们，如果你想聊聊智能体、构建、控制流或者任何相关的东西，随时可以找我。这就是12要素智能体。
