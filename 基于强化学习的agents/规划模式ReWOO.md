

## 规划模式：赋予 Agentic AI 掌控全局的能力

### **Agentic AI 设计模式系列（四）：规划模式**

这是 Agentic AI 设计模式系列的第四篇文章，我们将探讨 Agentic AI 的规划模式。在前两篇文章中，我们已经学习了智能体（Agent）如何进行反思（Reflection）和使用工具（Tool Use）来获取信息。在反思模式中，AI 智能体通过迭代生成和自我评估来提高输出质量。工具使用模式则使 AI 能够与外部系统、API 或资源进行交互，扩展其能力。

现在，我们来谈谈规划模式。想象一个智能助理，它不仅能反思并在需要时获取外部信息，还能决定解决更大问题的步骤顺序。很酷吧？更有趣的是：这个助理如何决定完成大型、多层次目标的最佳步骤顺序？有效的规划就是确定完成复杂、多步骤目标的结构化行动顺序。

#### **规划模式提供了什么？**

规划模式为语言模型提供了将大型任务分解为可管理的子目标的策略，使它们能够逐步解决复杂的挑战，同时关注总体目标。本文将详细讨论规划模式，包括 ReAct 和 ReWOO 技术。

#### **什么是 Agentic AI 规划模式？**

Agentic AI 规划模式是一个框架，专注于将大问题分解为较小的任务，有效地管理这些任务，并根据任务结果确保持续改进或适应。这个过程是迭代的，依赖于一个结构化的流程，以确保 AI 系统可以根据需要调整其计划，每次迭代都更接近期望的目标。

规划模式的主要组成部分：

1. **规划（Planning）：** 在初始阶段，AI 智能体解释提示并制定总体计划。该计划概述了 AI 打算如何解决问题，包括高级目标和策略。

2. **生成任务（Generate Task）：** 从计划中，AI 系统生成必须执行的特定任务。每个任务代表总体目标的一个较小、可管理的部分，使 AI 能够以集中的步骤工作。

3. **单一任务智能体（Single Task Agent）：** 单一任务智能体负责完成上一步生成的每个任务。该智能体使用预定义的方法（如 ReAct 或 ReWOO）执行每个任务。任务完成后，智能体返回一个任务结果（Task Result），该结果将被发送回规划循环。

4. **重新规划（Replan）：** 重新规划阶段评估任务结果，以确定是否需要进行任何调整。如果任务执行未完全满足预期结果，系统将重新规划并可能修改任务或策略。这个反馈循环使 AI 系统能够迭代学习和改进其方法，使其更能适应不断变化的需求或意外结果。

5. **迭代（Iterate）：** 模式的这一部分是连接“生成任务”和“重新规划”的循环。它表示该过程的迭代性质，其中 AI 系统不断重新评估和调整其方法，直到获得满意的结果。

Agentic AI 规划模式利用规划、任务生成、执行和重新规划的结构化循环，确保 AI 系统能够自主地朝着复杂目标努力。该模式通过允许 AI 根据任务结果修改其方法来支持适应性，使其对动态环境或不断变化的目标具有鲁棒性和响应性。

#### **Agentic AI 规划模式示例**

<img width="602" height="430" alt="image" src="https://github.com/user-attachments/assets/58401951-0df2-4a23-b600-28af413946f0" />


上图描绘了一个顺序图像理解过程，其步骤与 Agentic AI 规划模式一致。在 Agentic AI 中，"智能体" 根据观察和计划的响应采取行动，以实现特定目标。下面是图像中的每个步骤如何适应 Agentic AI 框架：

1. **目标设定（理解任务）**

- **提示：** 任务以一个问题开始：“你能描述这张图片并计算图片中有多少个物体吗？”

- **Agentic AI 元素：** AI 智能体将此目标解释为分析图像以进行对象识别和描述的指令。目标是通过识别、计数和描述对象来全面回答问题。

2. **规划和子目标形成**

- **过程分解：**

- 为了完成这个目标，智能体将任务分解为特定的子任务：

- 对象检测（识别和定位对象）
- 分类（识别每个对象是什么）
- 字幕生成（生成场景的自然语言描述）

- **Agentic AI 元素：** 智能体通过在 Agentic AI 规划模式中设置中间子目标来规划其行动。在这里，检测对象是完成最终目标（生成包含对象计数的描述性字幕）所需的子目标。

3. **感知和行动（检测和描述）**

- **使用的工具和模型：**

- 智能体利用`facebook/detr-resnet-101` 模型进行检测，该模型识别和定位对象（例如，长颈鹿和斑马）并分配置信度分数。
- 检测后，智能体使用`nlpconnect/vit-gpt2-image-captioning` 生成描述性字幕。

- **Agentic AI 元素：** 智能体使用特定的感知模块（预训练模型）“感知”其环境（图像），这些模块允许它收集必要的信息。在 Agentic AI 中，感知是一个主动的、面向目标的过程。在这里，模型充当感知工具，处理视觉信息以实现总体目标。

4. **评估和迭代（合并结果）**

- **处理和聚合信息：** 将检测结果（边界框和对象类型）和字幕生成结果（描述性文本）合并。智能体评估其输出，确认对象检测置信度水平和描述的连贯性。

- **Agentic AI 元素：** Agentic AI 涉及根据反馈和信息聚合持续评估和调整响应。智能体审查其预测（检测分数和边界框），以确保它们与任务的要求一致。

5. **目标达成（答案呈现）**

- **输出呈现：** 智能体最终提供一个答案，其中包括检测到的对象计数、具有置信度分数的已识别对象列表以及描述性字幕。

- **Agentic AI 元素：** 智能体通过将其感知和规划结果综合成一个连贯的响应来完成目标。在 Agentic AI 中，此步骤是关于实现任务的总体目标并生成解决用户初始问题的输出。

#### **Agentic AI 规划的任务分解**

有两种不同的 Agentic AI 规划任务分解方法，专门设计用于处理动态和可变现实环境中的复杂任务。鉴于尝试对复杂目标进行单步规划的局限性，分解为可管理的部分变得至关重要。这个过程类似于“分而治之”策略，涉及将复杂的目标分解为更小、更易于实现的子目标。

以下是对每种方法的解释：

##### **(a) 优先分解法 (Decomposition-First Approach)**

- **分解步骤：** 在这种方法中，LLM 智能体首先将主要目标完全分解为子目标（子目标 1、子目标 2、...、子目标 n），然后再启动子任务。此步骤在图中用 1 表示。

- **子计划步骤：** 分解任务后，智能体独立地为每个子目标创建子计划。这些子计划定义了实现每个子目标所需的具体行动。此规划过程在图中标记为 2。

- **顺序执行：** 每个子计划按顺序依次执行，按顺序完成每个子目标，直到完成主要目标。

本质上，优先分解法将分解和执行阶段分开：它在开始执行之前完成子目标的所有规划。这种方法在变化最小的稳定环境中可能有效。

##### **(b) 交错法 (Interleaved Approach)**

交错法中，分解和执行以更交织的方式发生：

- **同时规划和执行：** LLM 智能体不是在采取行动之前完全分解任务，而是从部分分解开始（例如，从子目标 1 开始），并立即开始规划和执行与此子目标相关的行动。

- **自适应分解：** 在处理每个子目标时，可能会识别和规划新的子目标，随着智能体的进展进行调整。智能体继续循环分解、规划和执行，允许灵活地响应变化或意外的环境复杂性。

- **动态执行：** 这种方法更具适应性，并且对不断变化的环境做出响应，因为规划和执行是交错的。这允许智能体根据实时反馈进行调整，根据需要修改子目标或行动。

简而言之：

- **优先分解法：** 一种结构化的、逐步的方法，在执行任何操作之前规划所有子目标。适用于任务定义明确且在执行期间不太可能发生变化的环境。

- **交错法：** 一种灵活的、自适应的方法，其中规划和执行同时发生。这种方法非常适合需要实时反馈和调整的动态环境。

在复杂的 AI 规划中，选择哪种方法取决于环境和任务的可变性。优先分解法强调结构和预先规划，而交错法则优先考虑适应性和实时响应能力。

这两种方法都有其自身的优势，但在面对高度动态和不可预测的场景时，它们也会带来独特的挑战。为了应对这种复杂性，一个名为 ReAct（Reasoning and Acting，推理和行动）的新兴框架在 AI 研究中变得越来越受欢迎。ReAct 以一种使智能体能够批判性地思考其行动的方式综合推理和行动，根据即时反馈调整其策略。这个框架将结构化规划与实时调整相结合，使智能体能够做出更复杂的决策，并处理各种环境中的可变性。

#### **什么是 ReAct？**

<img width="610" height="218" alt="image" src="https://github.com/user-attachments/assets/c4def8b5-d91e-48bb-835f-990df8c3dd03" />


我们已经知道，LLM 在提供语言理解和决策方面表现出令人印象深刻的能力。然而，它们推理和行动的能力一直是分开研究的课题。本节将讨论 LLM 如何使用推理和行动规划，通过 ReAct 方法更好地协同处理复杂任务。以下是 ReAct（Reason + Act）框架在语言模型（LM）系统中的演变和意义。它对比了传统方法（仅推理和仅行动模型）与 ReAct（结合了推理和行动能力）。让我们分解 ReAct 架构的每个部分，以了解它所传达的内容。

##### **ReAct 的工作流程**

1. **仅推理 (Reason Only)**

- 这种模型只关注语言模型内的推理和思维过程。这种方法的一个例子是思维链（CoT）提示，其中语言模型通过逻辑步骤来解决问题，但不直接与环境交互。

- 在这种仅推理模式下，模型生成一系列思想或“推理轨迹”，但无法采取行动或接收来自外部环境的反馈。它仅限于内部思考，没有参与。

- **局限性：** 由于它只进行推理，因此该模型无法根据实时反馈调整其行为或与外部系统交互，这使得它在需要交互的任务中缺乏动态性。

2. **仅行动 (Act Only)**

- 这种模型纯粹是为了在环境中行动而设计的。例子包括 WebGPT 和 SayCan 等系统，它们可以根据提示执行操作（例如，进行网络搜索和控制机器人）。

- 在这里，语言模型在外部环境（Env）中行动，采取行动，并观察这些行动的结果。然而，它没有推理轨迹来逻辑地指导其行动；它更多地依赖于直接的行动-响应，而没有更深入的规划。

- **局限性：** 没有推理，这种方法缺乏复杂、多步骤问题解决的能力。行动可能是反应性的，但缺乏可以提高长期有效性的战略思想。

3. **ReAct**

- ReAct 框架在单个循环中结合了推理和行动。在这里，语言模型在环境中的推理轨迹和行动之间交替进行。

- **过程：**

- 模型首先推理任务，创建关于下一步应该做什么的“想法”或假设。
- 然后，它根据其推理在环境中采取行动。
- 执行操作后，模型观察环境中的结果，并将其纳入其下一个推理步骤。
- 推理、行动和观察的循环持续迭代，使模型能够根据环境的实时反馈进行学习和适应。

- **意义：** 通过整合推理和行动，ReAct 使模型能够将复杂、多步骤的任务分解为可管理的步骤，根据结果进行调整，并朝着需要规划和交互的解决方案努力。这种组合使 ReAct 非常适合动态、多步骤的任务，在这些任务中，模型必须不断适应和改进其方法。

**为什么 ReAct 强大？**

<img width="725" height="574" alt="image" src="https://github.com/user-attachments/assets/5812f789-2eed-40f7-b642-f0d0f8a62ed7" />


ReAct 框架回答了图表底部提出的问题：如果我们结合推理和行动会怎么样？

通过整合这两种能力，ReAct 使模型能够以协调的方式思考和行动。这增强了其能力：

- 解决复杂问题。

- 根据反馈调整行动。

- 在需要顺序决策的环境中有效运作。

本质上，ReAct 通过将内部推理与外部行动相结合，提供了一种更全面的任务完成方法，使其在纯粹推理或行动模型不足的实际应用中更加灵活和有效。

通过同时利用推理和行动，ReACT（Reason + Act）方法优于其他方法。这使得 AI 能够适应动态环境和复杂问题。该框架可以产生更复杂和准确的结果，非常适合需要思考和交互的任务。

[ReAct Agent 使用 LlamaIndex 和 Gemini 的实现文章链接]

**使用 OpenAI API 和 httpx 库的规划模式**

本节旨在概述构建利用 OpenAI API 和 httpx 库的 AI 智能体的过程。它介绍了创建能够处理用户输入并通过 OpenAI 的语言模型执行响应的聊天机器人类的基本结构。本节解释了如何实现 ReAct 模式，以实现思想、行动、暂停和观察的循环。它描述了注册自定义操作（例如，维基百科搜索、计算、博客搜索）以增强功能。这促进了动态交互，其中智能体可以使用外部操作来改进和完成其答案。让我们直接进入构建 AI 智能体的基本结构：

（此处省略代码，因为代码主要用于实现，在知识地图中已经体现了实现细节）

**使用 LangChain 和 ReAct 的规划模式**

目标是使用 LangChain 和 OpenAI 的 GPT 模型实现一个工具增强的 AI 智能体，该智能体可以通过集成 Tavily API 等自定义工具进行网络搜索，从而自主进行研究并回答复杂问题。该智能体旨在通过执行称为 ReAct（推理和行动）的规划模式来模拟类似人类的问题解决。它构建了一个推理和行动步骤的循环，评估响应，并做出决策以有效地收集和分析信息。该设置支持实时数据查询和结构化决策，从而增强对诸如“自金球奖设立以来，获奖者的名字是什么？”等问题的回答。

如果您想深入了解生成式 AI，请探索：[GenAI Pinnacle Program 链接]

#### **ReWOO（Reasoning Without Observation）的工作流程**

<img width="780" height="421" alt="image" src="https://github.com/user-attachments/assets/1fd6cecc-6353-4525-b587-f6907b7331e7" />


ReWOO（Reasoning without Observation）是 Xu 等人提出的一种新的智能体架构，它强调在大型语言模型（LLM）系统中进行多步规划和变量替换的有效方法。它解决了 ReAct 式智能体架构中的一些局限性，特别是在执行效率和模型微调方面。以下是 ReWOO 如何改进传统方法的分解：

##### **ReWOO 如何工作？**

这是 ReWOO（Reasoning Without Observation）智能体模型的工作流程。该模型旨在通过最小化冗余观察并专注于计划的行动序列来提高多步推理和工具使用的效率。以下是每个组件以及信息流的逐步说明：

##### **ReWOO 的组件**

- **规划器（Planner）：**

- 规划器负责在开始时创建整个计划。它确定解决任务所需的行动或步骤序列。
- 对于每个行动步骤，规划器指定：

- **工具：** 该步骤所需的特定工具或功能。
- **参数（args）：** 工具所需的输入值或变量。

- 该计划使用变量替换来定义，其中一个工具的输出（例如，#E1）可以用作另一个工具的参数（例如，#E2），从而在步骤之间创建依赖关系。
- 重要的是，此规划过程在单个 LLM 调用中发生，通过减少 token 消耗使其比基于观察的迭代推理更有效。

- **工作器（Worker）：**

- 工作器负责根据规划器生成的计划执行操作。
- 工作器获取为每个步骤提供的参数，调用指定的工具，并返回结果。
- 此执行可以循环进行，直到任务解决，确保每个工具操作都按照计划中概述的正确顺序完成。
- 工作器独立于 LLM 运行，这意味着它只是遵循规划器的指令，而无需在每个步骤中额外调用 LLM。

- **求解器（Solver）：**

- 求解器是解释工作器使用的工具结果的最终组件。
- 根据从工具执行中收集的观察结果，求解器生成用户查询或任务的最终答案。
- 此部分可能涉及最终的 LLM 调用，以将信息合成为连贯的响应。

##### **ReWOO 的关键增强**

以下是 ReWOO 的关键增强：

- **高效的工具使用和减少的 token 消耗：**

- **单次工具生成：** 与 ReAct 式智能体不同，后者需要对每个推理步骤进行多次 LLM 调用（因此每次调用都会重复整个系统提示和之前的步骤），ReWOO 在一次传递中生成所需工具的完整序列。
- 这种方法大大减少了 token 消耗并缩短了执行时间，使其更适合涉及多个步骤或工具的复杂任务。

- **简化的微调过程：**

- **将规划与工具输出解耦：** 由于 ReWOO 的规划数据不依赖于工具的实际输出，因此它允许更直接的微调过程。
- **无需工具执行的微调：** 从理论上讲，可以在不调用任何工具的情况下对模型进行微调，因为它依赖于计划的操作和替换，而不是实际的工具响应。

##### **工作流程**

该过程通过以下步骤进行：

1. **步骤 1 – 用户输入：**

- 用户向 ReWOO 提交问题或任务。

- 输入被传递给规划器以启动规划阶段。

2. **步骤 2 – 规划器创建计划：

- 规划器制定多步计划，指定要使用的工具和所需的参数。

- 该计划可能涉及变量替换，其中一个工具的输出用作另一个工具的输入。

- 然后，规划器将此完整计划提供给工作器。

3. **步骤 3 – 工作器执行操作：**

- 工作器通过使用适当的参数调用指定的工具来执行计划的每个步骤。

- 这个循环过程确保每个工具操作按顺序完成，直到任务完成。

4. **步骤 4 – 求解器生成答案：**

- 执行完所有必要的操作后，求解器会解释结果并为用户生成最终答案。

- 然后将此答案返回给用户，完成工作流程。

本质上，ReWOO 通过分离推理（规划器）和执行（工作器）阶段来提高智能体的效率，从而为复杂任务创建一个更快、更节省资源的框架。

##### **有观察的推理和 ReWOO 的比较**

<img width="728" height="475" alt="image" src="https://github.com/user-attachments/assets/3809bc39-ef11-4082-a6d5-846ebee99a12" />


在涉及大型语言模型（LLM）的系统中，任务推理的两种不同方法是 (a) 有观察的推理和 (b) ReWOO（有观察和有组织证据的推理）。以下是基于给定图表的比较：

1. **依赖观察的推理（左侧面板）**

- **设置和流程：**

- 首先使用上下文和范例（示例或提示以帮助 LLM 的推理）增强用户的任务，然后将其输入到 LLM 以开始推理过程。
- LLM 生成两个关键输出：

- **T（Thought）：** 表示从 LLM 的初始处理中得出的内部思想或理解。
- **A（Action）：** 这是 LLM 根据其思想决定采取的行动，通常涉及查询工具以获取信息。

- 每次操作后，都会收到来自工具的观察结果（O）。此观察结果充当反馈循环，并附加到提示历史记录中，形成下一次 LLM 调用的更新输入。

- **迭代性质：**

- 此设置是迭代的，这意味着 LLM 会重复循环思考、行动和观察，直到获得足够的推理。
- 每个循环都依赖于在提示历史记录中不断堆叠观察结果，随着时间的推移积累更多信息，从而产生提示冗余。

- **局限性：**

- 由于每次循环都会重复输入相同的上下文和范例，因此这种方法可能会导致提示冗余和潜在的低效率，因为相同的数据（上下文和范例）会反复反馈到系统中。

2. **ReWOO（右侧面板）**

- **增强结构：**

- 与依赖观察的推理设置不同，ReWOO 通过分离角色引入了一种更结构化的方法：

- **规划器：** 负责创建一系列相互依赖的计划（P）。
- **工作器：** 根据规划器的指示从各种工具中获取证据（E）。

- 规划器生成计划，然后将其传递给工作器。工作器通过工具交互收集必要的证据来执行这些计划。

- **计划和证据的作用：**

- **计划（P）：** 这些是预定义的、相互依赖的步骤，概述了系统的推理路径。
- **证据（E）：** 这是根据规划器的指示检索到的特定信息或数据。
- 计划（P）和证据（E）的组合形成了一个更有组织的输入，它与原始任务和上下文一起，最终由求解器 LLM 处理以生成用户的输出。

- **求解器：**

- 求解器充当最终的推理模块，整合任务、上下文、计划和证据以生成连贯的答案。
- 由于上下文和范例不会重复输入到 LLM 中，因此 ReWOO 减少了提示冗余的问题。

**ReWOO 的主要区别和优势**

- **提示效率：**

- 依赖观察的推理会因重复循环相同的上下文和范例而遭受提示冗余，这可能会使提示过载并增加处理时间。
- 另一方面，ReWOO 通过分离规划和证据收集阶段来避免这种冗余，使提示更有效率。

- **结构化任务执行：**

- ReWOO 的设计引入了规划器和工作器，允许在任务规划和证据收集之间进行明确区分。这种结构化的流程确保每个步骤都按逻辑执行，从而更容易管理复杂的任务。

- **可扩展性：**

- 凭借其模块化设置，ReWOO 可以有效地处理更复杂的任务。其结构化的规划和证据检索方法使其能够更好地扩展复杂的推理任务，因为每个组件（规划器、工作器、求解器）都有明确的角色。

**总结**

- **依赖观察的推理：** 循环思考、行动和观察，产生提示冗余但保持简单性。

- **ReWOO：** 通过使用规划器、工作器和求解器来简化推理、减少提示冗余并提高处理复杂任务的效率，从而使用更有组织的结构。

**ReWOO 的代码实现**

由于之前的示例已经涵盖了 OpenAI API + httpx 和 LangChain 的 ReAct 实现，对于 ReWOO，可以参考 Vadym Barda 的 ReWOO 方案，使用 LangGraph。此处强调的是，实现 ReWOO 的关键在于定义好状态图（StateGraph），包括规划器（Planner）、执行器（Executor）和求解器（Solver）的逻辑。

#### **Agentic AI 规划模式的优点和局限性**

Agentic AI 规划模式提供了显著的优势，特别是当任务的复杂性阻止了预先确定的逐步分解时。 规划使智能体能够动态地决定其行动方案，从而实现自适应和上下文感知的问题解决。 它增强了处理不可预测任务的灵活性和能力，使其成为需要战略远见和决策的情况下的强大工具。

然而，这种能力伴随着明显的局限性。 规划的动态特性引入了不可预测性，使得更难预测智能体在任何给定场景中的行为方式。 与更具确定性的 Agentic 工作流（例如反思或工具使用）不同，规划仍然不太成熟，并且可能会产生不一致的结果。 虽然当前的规划能力提出了挑战，但 AI 研究的快速发展表明，这些局限性可能会随着时间的推移而减少，从而产生更强大和可预测的规划功能。
