https://www.youtube.com/watch?v=D7_ipDqhtwk

该内容围绕“如何构建高效智能体”展开，结合实践经验梳理了核心原则、实用方法及未来趋势，以下是详细总结：


### 一、智能体的发展阶段与核心特征
1. **演进路径**  
   - **基础阶段**：2-3年前以简单功能（摘要、分类、提取）为主，现已成为基础能力；  
   - **工作流阶段**：通过预定义控制流编排多个模型调用，平衡成本、延迟与性能，是智能体系统的雏形；  
   - **当前阶段**：领域特定智能体进入生产环境，可自主决定行动轨迹，基于环境反馈独立运行（核心特征：自主性、动态决策）；  
   - **未来趋势**：可能向“通用智能体”或“多智能体协作”演进，但核心是“自主性提升→价值与风险同步增加”。

2. **与工作流的核心区别**  
   工作流是“预定义控制流”，路径固定；智能体是“自主决策流”，可根据反馈调整轨迹，更灵活但成本、复杂度更高。


### 二、核心原则一：不要为所有场景构建智能体（用例筛选标准）
智能体仅适用于“复杂、高价值、可容错”的任务，需通过以下 checklist 筛选：

1. **任务复杂度**  
   - 适合智能体：任务模糊、决策路径不固定（如从设计文档生成代码PR）；  
   - 不适合：可通过明确决策树或脚本解决（如固定流程的数据分析）。

2. **任务价值**  
   智能体需消耗大量 tokens（成本高），需任务价值覆盖成本。例如：  
   - 适合：编程（优质代码价值高）、复杂数据分析（决策影响大）；  
   - 不适合：低价值高频场景（如简单客服问答，可用工作流替代）。

3. **关键能力可行性**  
   需提前验证智能体的核心能力无瓶颈。例如编程智能体需能“写代码、调试、从错误中恢复”，否则会因反复试错增加成本。

4. **错误成本与可发现性**  
   - 若错误后果严重（如金融交易）或错误难验证（如模糊内容生成），需限制智能体权限（如只读、人工审核），但会降低效率；  
   - 适合场景：错误易验证（如编程，可通过单元测试校验）。


### 三、核心原则二：保持架构简单（最小可行智能体设计）
智能体的核心架构仅需3个组件，复杂度会降低迭代效率，需优先保证基础组件稳定：

1. **三大核心组件**  

   - **环境**：智能体运行的系统（如编程智能体的代码仓库、客服智能体的对话系统）；  
   - **工具**：智能体与环境交互的接口（如“代码生成”“文件读取”工具），需明确功能与参数；  
   - **系统提示**：定义智能体的目标、约束与行为准则（如“生成符合Python规范的代码，避免使用未定义变量”）。

2. **迭代逻辑**  

   先通过“模型调用工具的循环”实现基础功能，再优化细节（如并行工具调用降延迟、轨迹记录降成本），而非一开始堆砌复杂功能。

3. **优势**  

   相同核心架构可适配不同场景（如编程、客服、数据分析），仅需调整“环境、工具、提示”，复用代码提高效率。


### 四、核心原则三：站在智能体的角度思考（优化与调试方法）
智能体的决策基于“有限上下文”，需模拟其视角以发现问题：

1. **模拟智能体的认知局限**  
   - 智能体仅能基于“当前上下文（如截图、历史对话）+工具反馈”决策，类似“闭眼前操作电脑，睁眼仅见结果”；  
   - 实践方法：手动模拟智能体执行任务（如仅用截图+模糊指令操作软件），发现其需要的关键信息（如屏幕分辨率、操作限制）。

2. **用模型反向验证**  
   直接向大语言模型（如GPT）提问，模拟智能体视角：  
   - 检查提示是否清晰：“这个任务描述有歧义吗？”  
   - 验证工具可用性：“这个工具的参数是否足够？需要补充什么？”  
   - 分析决策原因：“为什么你在这个步骤选择调用工具A而非B？”


### 五、未来方向与开放性问题
1. **预算可控性**  
   需解决“智能体自主决策导致成本/延迟不可控”，例如定义“最大tokens消耗”“最长执行时间”等约束。

2. **自我进化工具**  
   让智能体自主优化工具（如根据任务调整工具参数、设计新工具），提升通用性。

3. **多智能体协作**  
   需解决“智能体间通信方式”（如同步指令？异步消息？），以及职责划分（如主智能体分配任务，子智能体执行细节）。


### 总结：构建高效智能体的关键
1. 先通过 checklist 筛选适合的用例（复杂、高价值、可验证）；  
2. 以“环境+工具+提示”为核心架构，保持简单再优化；  
3. 站在智能体的有限上下文视角调试，而非以人类认知判断；  
4. 未来需解决成本可控、工具进化、多智能体协作三大问题。


[音乐]

能和这么多我一直学习的对象同台，真是太棒了。我们言归正传，我叫巴里，今天我们要聊聊如何构建高效的智能体。大约两个月前，我和埃里克写了一篇名为《构建高效智能体》的博客，在文中我们分享了关于“智能体是什么、不是什么”的一些独到见解，以及我们在实践中获得的实用经验。今天，我想深入探讨博客中的三个核心观点，并在最后分享一些个人思考。

这三个核心观点分别是：第一，不要为所有事情都构建智能体；第二，保持简单；第三，站在智能体的角度思考。

我们先回顾一下发展历程。我们大多数人可能都是从构建非常简单的功能起步的，比如摘要生成、分类、提取，这些在两三年前还让人觉得很神奇的功能，现在已经成了基本技能。随着我们技术的成熟和产品的完善，我们的想法也越来越有创意。一次模型调用往往不够，所以我们开始按预先定义的控制流程编排多次模型调用。这基本上让我们能够在成本和延迟之间进行权衡，以获得更好的性能，我们称之为“工作流”。我们认为这是智能体系统的开端。

现在，模型的能力越来越强，我们看到越来越多特定领域的智能体在生产环境中出现。与工作流不同，智能体可以自主决定行动轨迹，并根据环境反馈几乎独立地运行。这将是我们今天关注的重点。

要确定智能体系统的下一阶段会是什么样子，可能还为时过早，尤其是在生产环境中。单个智能体可能会变得更具通用性和能力，或者我们可能会看到多智能体之间的协作和任务委派。无论如何，我认为大趋势是，当我们赋予这些系统更多自主性时，它们会变得更有用、更强大，但随之而来的是成本、延迟以及错误带来的后果也会增加。

这就引出了第一个观点：不要为所有事情都构建智能体。为什么呢？我们认为智能体是一种用于扩展复杂且有价值任务的工具，它们不应该成为所有用例的“即插即用”式升级。如果你读过我们的博客，就会知道我们经常提到工作流，那是因为我们真的很认可工作流，而且在当下，工作流是一种能很好地创造价值的具体方式。

那么，什么时候应该构建智能体呢？这里有一个参考清单。首先要考虑的是任务的复杂性。智能体在模糊的问题领域中才能大显身手，如果你能很容易地画出整个决策树，那就直接明确地构建出来，并优化决策树的每个节点，这样成本效益更高，也能获得更多控制权。

接下来要考虑的是任务的价值。我刚才提到的探索过程会消耗大量的标记（tokens），所以任务本身必须值得投入这些成本。例如，如果你的每项任务预算在10美分左右，比如你正在构建一个高容量的客户支持系统，这只能让你使用3万到5万个标记，那么在这种情况下，只需使用工作流来解决最常见的场景，就能抓住大部分价值。不过，另一方面，如果你看到这个问题的第一反应是“我不在乎消耗多少标记，我只想要完成任务”，那请会后找我，我们的市场团队很乐意和你交流。

然后，我们要降低关键能力的风险。这是为了确保智能体的行动轨迹不会出现重大瓶颈。如果你在做一个编程智能体，你要确保它能够写出优质代码、能够调试，并且能够从错误中恢复。即使存在瓶颈，可能也不会是致命的，但会增加成本和延迟。所以在这种情况下，我们通常会缩小范围、简化任务，然后再试一次。

最后，需要考虑错误成本和错误发现难度。如果错误的风险很高，而且很难发现，那么你就很难信任智能体代表你采取行动并赋予它更多自主权。你当然可以通过限制范围来缓解这个问题，比如设置只读权限、增加人工介入环节，但这也会限制智能体在你的用例中的扩展能力。

让我们看看这个清单在实际中的应用。为什么编程是智能体的绝佳用例？首先，从设计文档到提交PR（拉取请求），显然是一项非常模糊且复杂的任务。其次，我们这里很多人都是开发者，都知道优质代码具有很高的价值。再者，我们很多人已经在云端进行编程工作，知道云在编程工作流的很多环节都表现出色。最后，编程有一个很好的特性，就是输出可以通过单元测试和持续集成（CI）轻松验证。这可能就是我们现在看到这么多富有创意且成功的编程智能体的原因。

一旦你找到了适合智能体的好的用例，就到了第二个核心观点：尽可能保持简单。我来给大家解释一下。在我们看来，智能体就是模型在循环中使用工具。在这个框架中，三个组件定义了智能体的本质：首先是环境，即智能体运行的系统；其次是一组工具，为智能体提供行动和获取反馈的接口；然后是系统提示，它定义了智能体在该环境中工作的目标、约束条件和理想行为。之后，模型在循环中被调用，这就是智能体。

我们从惨痛的教训中学会了保持简单，因为前期的任何复杂性都会严重影响迭代速度。只迭代这三个基本组件，能给你带来最高的投资回报率，优化可以稍后进行。

这里有三个我们为自己或客户构建的智能体用例示例，为了更具体地说明问题。它们在产品表面、范围和能力上看起来可能大不相同，但它们几乎拥有完全相同的核心架构，实际上使用的代码也几乎完全一样。环境在很大程度上取决于你的用例，所以真正的设计决策只有两个：一是你想为智能体提供哪些工具；二是你想用什么样的提示来指导智能体。

说到这里，如果你想了解更多关于工具的知识，我的朋友马赫什明天早上将举办一个关于模型上下文协议（MCP）的研讨会。我看过那个研讨会的内容，会非常有趣，所以强烈推荐大家去看看。回到我们的话题，一旦你确定了这三个基本组件，接下来就有很多优化工作可以做。比如对于编程和计算机使用相关的智能体，你可能需要跟踪行动轨迹以降低成本；对于有大量工具调用的搜索类智能体，你可以并行处理很多调用以减少延迟；而且对于几乎所有智能体，我们都希望以一种能获得用户信任的方式展示其工作进度。总之，在迭代过程中，先构建这三个组件，等确定了行为之后再进行优化。

最后一个观点是：站在智能体的角度思考。我见过很多开发者，包括我自己，都是从自己的角度开发智能体，当智能体出错时就会感到困惑，因为智能体的错误在我们看来似乎不合常理。这就是为什么我们总是建议设身处地地站在智能体的上下文窗口中思考。智能体可以表现出一些非常复杂的行为，看起来极其复杂，但在每一步，模型所做的不过是基于有限的上下文进行推理。

模型对当前世界状态的所有认知，都体现在那1万到2万个标记中。把自己限制在这个上下文中，看看这些信息是否足够且连贯，这会让你更清楚地了解智能体是如何看待世界的，从而弥合我们与智能体之间的认知差距。

我们来想象一下，假设我们是计算机使用智能体，会是什么感觉。我们只会得到一张静态截图和一段写得很糟糕的描述（这段描述是我写的）。我们可以尽情思考和讨论，但唯一能对环境产生影响的只有我们的工具。所以我们尝试点击，但实际上并不知道会发生什么。在推理和工具执行的过程中，这基本上就相当于我们闭上眼睛3到5秒，在黑暗中操作电脑。然后睁开眼睛，看到另一张截图，不管我们刚才做了什么，可能成功了，也可能把电脑关掉了，我们根本不知道。这是一个很大的盲区，然后这个循环又开始了。

我强烈建议大家从智能体的角度完整地执行一项任务。我保证这会是一次很有趣且只是稍微有点不舒服的体验。不过，一旦经历了这种稍微不舒服的体验，你就会清楚地知道智能体真正需要什么。显然，知道屏幕分辨率非常重要，这样才能知道该点击哪里；提供推荐的行动和限制条件也很好，这样我们就能知道应该探索哪些内容，避免不必要的探索。这些只是一些例子，你可以针对自己的智能体用例做这个练习，弄清楚你实际上应该为智能体提供什么样的上下文。

幸运的是，我们正在构建的是能理解我们语言的系统，所以我们可以直接让模型（比如Cloud）来理解。你可以输入系统提示，问模型：“这些指令有不明确的地方吗？对你来说有意义吗？你能遵循这些指令吗？”你可以输入工具描述，看看智能体是否知道如何使用该工具，看看它是否需要更多或更少的参数。我们经常做的一件事是，把智能体的整个行动轨迹输入给模型，然后问：“你认为自己在这里为什么会做出这个决定？有没有什么我们可以做的来帮助你做出更好的决定？”

这虽然不能替代你自己对上下文的理解，但会帮助你更贴近地了解智能体是如何看待世界的。所以，在迭代过程中，一定要站在智能体的角度思考。

好了，我大部分时间都在讲非常实用的内容，现在我想放纵一下自己，用一张幻灯片分享一些个人思考。这是我对智能体发展趋势的看法，以及作为人工智能工程师我们需要共同回答的一些开放性问题。

有三件事一直萦绕在我的脑海中。第一，我认为我们需要让智能体更具预算意识。与工作流不同，我们对智能体的成本和延迟并没有很好的控制感。我认为解决这个问题将催生更多用例，因为这能让我们获得在生产环境部署智能体所需的必要控制权。开放性问题是，以什么方式定义和执行预算最好，是从时间、金钱还是从我们关心的标记数量等方面？

接下来是“自我进化的工具”这个概念。我在前两张幻灯片中已经有所暗示，我们已经在使用模型来帮助优化工具描述，但这应该能很好地推广到元工具，即智能体可以设计和改进自己的工具使用方式。这将使智能体更具通用性，因为它们可以根据每个用例采用所需的工具。

最后，我甚至觉得这已经不算什么大胆的预测了，我个人坚信，到今年年底，我们会在生产环境中看到更多多智能体协作的场景。它们具有很好的并行性和明确的职责划分，例如，子智能体的存在确实能保护主智能体的上下文窗口。但我认为一个重要的开放性问题是，这些智能体之间实际上是如何通信的？我们目前还处于一种非常僵化的模式，主要是同步的“用户-助手”模式，而且我们的大多数系统都是围绕这种模式构建的。那么，我们如何突破这种模式，建立异步通信，并赋予智能体更多角色，使它们能够相互交流和识别？我认为这将是我们在探索多智能体未来时面临的一个重大问题。

这些是我一直在思考的领域，如果你也在思考这些问题，欢迎给我发信息，我很乐意交流。

好了，我们来总结一下。如果今天我说的你都忘了，记住这三个要点就行：第一，不要为所有事情都构建智能体；第二，如果你找到了合适的用例并想要构建智能体，尽可能长时间地保持简单；第三，在迭代过程中，站在智能体的角度思考，理解它们的视角，帮助它们更好地完成工作。

我很乐意和大家保持联系，如果你想聊聊智能体，尤其是我刚才提到的那些开放性问题，那将非常棒，我们可以一起探讨这些想法。这是我的社交账号，欢迎大家联系。

最后，我用一个个人轶事来结束今天的演讲。2023年，我在Meta从事人工智能产品开发，当时我们有个有趣的规定，就是可以把自己的职位描述改成任何想要的。在读了斯威克斯的博客后，我决定成为“首位人工智能工程师”。我真的很欣赏那种注重实用性、致力于让人工智能真正对世界有用的理念，而且我认为……



