Dify AI 作为一个强大的 LLM 应用开发平台，提供了包括知识库在内的一系列开箱即用的功能，极大的简化了 AI 应用的构建流程。它提供了整个 AI 应用的全生命周期的管理。
1. 对话历史管理
2. 应用管理（对话、工作流）
3. 工具调用能力
4. 知识库管理能力

然而，随着应用规模的扩大、数据量的增长以及对搜索精度和用户体验的提升，Dify 开箱即用的知识库功能在某些情况下也显露了局限性。我们通过一系列的方案里逐步增强知识库的功能，

**本文中的增强不仅包含工程上的增强，也包含了用户体验上的增强。**

#### 如何构建与检索

在对知识库功能进行增强前，我们先梳理一下一个典型的 RAG 知识库的处理流程：

1. **数据获取与加载 (Data Ingestion & Loading)** :
- 从各种来源（文件、数据库、网页、API）加载原始文档。
- 提取核心文本内容，并关联重要的元数据（如来源、日期、分类）。

2. **文档处理与索引 (Document Processing & Indexing)** :
- **文档分割/分块 (Chunking)** : 将长文档切分成更小的、语义集中的文本块。这是为了适应 LLM 的上下文窗口限制，并提高检索精度。常用的策略有固定大小、递归字符分割、语义分块等。
- **向量化 (Embedding)** : 使用嵌入模型将每个文本块转换为高维向量，捕捉其语义信息。这些向量通常存储在专门的向量数据库中，用于相似性搜索。
- **关键词索引 (Keyword Indexing)** : 对文本块建立传统的倒排索引，以支持快速的关键词匹配。它可以将文本块内容和元数据一起索引，提供高效的关键词搜索、过滤和排序能力，弥补纯向量搜索在精确匹配上的不足。

3. **检索/召回 (Retrieval / Recall)** :
- **查询处理** : 将用户查询进行向量化和/或提取关键词。
- **执行搜索** :
- **向量搜索** : 在向量数据库中查找语义最相似的文本块。
- **关键词搜索** : 在**Meilisearch** 或类似引擎中查找包含查询关键词的文本块，利用其内置的相关性排序和容错能力。
- **混合搜索 (Hybrid Search)** :**结合向量搜索和关键词搜索的结果** ，通过融合策略（如 RRF）获得更全面、更精准的召回列表。这是目前 RAG 的最佳实践之一。
- **过滤** : 利用**Meilisearch** 强大的过滤功能，根据元数据（如分类、时间）精确筛选召回结果。
- **重排 (Re-ranking)** : 使用更复杂的模型对初步召回的结果进行二次排序，进一步提升相关性。

4. **生成 (Generation)** :
- 将最终筛选出的最相关的知识片段（通常来自混合搜索和重排）作为上下文，连同用户查询一起构建 Prompt。
- 将 Prompt 发送给 LLM（如 Dify 中配置的模型）生成最终答案。

理解这个流程有助于我们认识到，知识库的性能和效果不仅仅取决于向量化和向量存储，**高效的文本索引、灵活的检索策略（特别是混合搜索）以及强大的过滤能力同样至关重要** 。
