- 推荐系统-召回+排序+精排

检索，多路召回

重点是文档结构和对应文本解析

chunk,标点和长度

普通文档场景bge-v3


bm25 和dense rerank


上下文拼接： 召回是chunk，拼接式chunk对应的content，依赖于一个好的文档结构解析来界定chunk对应的content

多跳:agentic rag

嵌入前对文件进行处理

第三人称换成具体的名词


chunk分块，固定分块，文本结构正则分块，文件内容少的，相对独立的，一个文件一个块，

语义分块优化，根据文件需求场景切分数据，原先数据做一层梳理，切分后维护标签做分块分组

多跳，top-k太松，看场景试配的召回方式


rerank处理，

多跳的压缩上下文，摘要聚合，结合query改写回答


sestancetransfomer

BAAI

text-embedding-002/large/small

图片多模态ebedding

用多模态的llm或者ocr等把图片转换成为文本

# 分块策略适合绝大部分

1.固定长度+滑动窗口

2.递归字符切分（按照段落-》句子->字符）

3.基于句子的语义切分

4.Markdown结构感知切分

5.基于查询的动态切分，query-aware


功的企业级RAG，其核心瓶颈不在于单个算法的优劣，而在于顶层 "知识治理架构" 的缺失。

个懂得"分而治之"的联邦式知识系统，而非一个庞大、笨拙、试图用一种方法治疗百病的单一RAG系统。高效分诊台和各类专科专家的现代化医院。

企业知识的"大脑皮层"：负责接收所有输入信号（用户查询），进行快速的分析、理解和决策，然后将指令精准地传达给相应的"功能区"（专家RAG管道）。

知识团队的"CEO"：它不亲自执行每一个任务，但它决定了"什么事应该由谁来做"，确保公司的资源（检索和算力）被用在最合适的地方，以最高效的方式解决问题。



# 职责一：查询意图分析 (Query Intent Analysis)
这是调度中心的第一步，也是至关重要的一步。当一个查询进入系统时，它不会立刻冲进向量数据库里进行"暴力"搜索。相反，一个轻量级的、专门用于分类的语言模型会先对这个查询进行"体检"。

目标：判断用户的真实意图，并将查询归类到一个或多个预定义的"知识领域"。

### 构建你的查询意图分析器

以下是表格所有文字内容：
|实现策略|核心做法|优点|缺点|最佳适用场景|
| ---- | ---- | ---- | ---- | ---- |
|LLM 零/少样本分类|通过精心设计的提示（Prompt），让一个强大的 LLM（如 GPT - 4，Claude 3）直接判断查询应路由到哪个“专家小队”。|实现快、灵活性高。无需训练数据，能理解复杂口语化查询，可随时增删路由规则。|成本与延迟较高。每次路由都需要一次强大的 LLM API 调用。|快速原型验证、业务场景复杂多变、或查询量不大的内部系统。|
|嵌入相似度路由|将每个“专家小队”的描述文本进行嵌入，形成“领域向量”。计算用户查询向量与这些领域向量的相似度，选择最相似的进行路由。|速度快、成本极低。仅需一次嵌入调用和向量计算。|对边界模糊的查询效果一般，强依赖于“领域描述”的撰写质量。|拥有明确领域边界、查询量大、对延迟和成本敏感的场景。|
|微调分类模型|标注一批查询数据（查询文本 -> 对应小队），用这些数据微调一个轻量级的分类模型（如 DistilBERT）。|速度极快、成本最低，在特定任务上可达极高精度。|灵活性差、维护成本高。需要数据标注，增删规则需要重新训练模型。|业务领域非常固定、追求极致性能和低成本的大规模线上应用。|
|混合/层级路由|结合多种方法。例如，先用简单的关键词规则进行初步筛选，无法判断的再交由 LLM 处理。|在成本、性能和灵活性之间取得最佳平衡。|系统逻辑更复杂，需要设计好多层路由的规则和回退机制。|大多数成熟的、复杂的生产系统，需要兼顾各种情况。|

<img width="467" height="423" alt="image" src="https://github.com/user-attachments/assets/60ed78a9-008a-4bb4-9e53-cb768c249e92" />


<img width="877" height="572" alt="image" src="https://github.com/user-attachments/assets/bf96c812-2e82-48b6-918b-685d6217a7dd" />


对于绝大多数刚刚起步构建此架构的团队，强烈建议从 LLM 零/少样本分类 开始。它的实现成本最低，可以让你迅速验证整个联邦式架构的价值。当系统流量增大或对成本、延迟有更高要求时，再逐步考虑引入嵌入路由或混合路由进行优化。

# 职责二：分派至专家RAG管道 (Dispatch to Specialized RAG Pipelines)

在完成意图分析后，调度中心就拿到了清晰的"诊断报告"。现在，它可以像一位经验丰富的总调度师一样，发出精准的指令。
目标：将分析后的查询，连同其上下文（如识别出的领域、时间等），分派给一个或多个最适合处理它的"RAG专家小队"。
续上例：
调度中心的工作流如下：
指令1 -> 产品专家小队: "检索知识库中关于'星尘'系列产品的核心技术文档和发布日期信息。"
指令2 -> 客服专家小队: "在你的知识库中，检索所有与'星尘'系列产品相关，且时间戳在'上季度'内的用户投诉记录。"
结果汇集与综合：调度中心收集来自两个专家小队的检索结果。这些结果不是最终答案，而是高质量、高相关的原始材料。
最终生成：将这些从不同领域精准检索出的材料，连同原始查询，一起提交给一个强大的生成模型（LLM），由它来综合这些信息，生成最终的、条理清晰的答案。

# 建立组织概念："RAG专家小队"的诞生
在上面的例子中，我们反复提到了一个新概念："RAG专家小队" (Specialized RAG Squads)。

这正是"智能知识路由与调度中心"这个大脑所指挥的"双手双脚"。它们不是抽象的概念，而是可以被具体构建和优化的独立RAG管道。每一个小队都代表着一个为特定知识领域量身定制的、从数据处理到检索策略都深度优化的解决方案。

例如：

财务专家小队：它的数据管道可能强制使用能解析表格的工具，其切片策略严格遵循财报的章节结构。

客服专家小队：它的数据管道可能优先使用"语义切片"来聚合相似的投诉，并使用"滑动窗口"来保持对话的连续性。


这个"联邦制"的架构带来了巨大的好处：

精确性 (Precision)：每个小队都在自己最擅长的领域工作，检索结果的相关性大大提高。

*可扩展性 (Scalability)**E：当公司出现新的业务线或知识领域（例如，可持续发展报告）时，我们不需要推倒重来，只需创建一个新的"专家小队"并将其注册到调度中心即可。

可维护性 (Maintainability)：我们可以独立地优化和迭代每一个小队的性能，而不会影响到其他团队。

# 各司其职：组建AI驱动的"RAG专家小队

## 核心蓝图：四大知识领域的"专家小队"配置指南
企业知识并非铁板一块，因此，我们的"专家小队"也必须各有专长。以下表格是整个组织篇的核心，它详细说明了如何为企业最典型的四类知识领域，分别组建其专家小队，并配置最适合它们的处理与切片策略。

|企业知识领域|文档类型|核心切片策略|深入见解与独到策略|
| ---- | ---- | ---- | ---- |
|财务/法律小队|高度结构化的文档|1. 结构化切片<br>2. 元数据增强切片<br>3. 特定模态切片|洞察:对于财报，数字和表格就是生命线。必须使用特定模态切片将表格完整提取为独立对象。对于法律文件，条款编号和合同结构是关键，结构化切片应严格遵循文档的章节层级。元数据（如财报季度、合同签署日期）是实现精确过滤查询的生命线，必须强制应用。|
|产品/API小队|高度结构化的文档/代码库|1. 结构化切片（AST或Markdown）<br>2. 父文档检索器<br>3. 递归切片（代码优化）|洞察:这类文档的结构本身就蕴含着功能逻辑。使用基于AST的结构化切片处理代码，或基于标题的结构化切片处理说明书是最佳选择。父文档检索器在此处是"杀手级应用"：当用户查询某个具体函数时（子块），系统返回其所属的整个类或功能模块的说明（父块），提供最完整的上下文。|
|客服/反馈小队|非结构化文档|1. 语义切片<br>2. 滑动窗口切片<br>3. 元数据增强切片|洞察:这类数据的价值在于发现趋势和情感。语义切片是首选，因为它能将语义相关（即使措辞不同）的投诉或建议聚合在一起。对于对话记录，必须采用滑动窗口，以保持上下文的连贯性。元数据（用户ID、时间戳、产品线）至关重要，它使得"查询某产品在特定时间段的用户反馈"成为可能。|
|通用知识小队|半结构化文档|1. 递归切片|洞察:这是最通用的知识领域，如公司介绍、新闻稿等，通常是叙事性的。递归切片以其对段落和句子的良好适应性，成为最稳健和高效的基准策略。它很好地平衡了实现成本和效果，是所有团队的保底选择。| 


## 深度剖析：当"律师"遇上"心理学家"
为了更深刻地理解"因材施教"的重要性，让我们挑选上表中两个性格迥异的团队——"财务/法律专家小队"和"客服/反馈专家小队"——进行一次面对面的对比。这就像是让一个严谨的"律师"和一个善于共情的"心理学家"来处理同一个问题，他们的工具、方法和关注点将完全不同。

|对比维度|财务/法律小队（严谨的律师）|客服/反馈小队（共情的心理学家）|为什么差异如此巨大?|
| ---- | ---- | ---- | ---- |
|数据核心价值|事实的精确性。数字、条款、日期，一个都不能错。|意图和情感的捕捉。用户真正在抱怨什么？他们的情绪是怎样的？|两者的目标南辕北辙。前者是"是什么"，要求100%忠于原文；后者是"为什么"，要求能从杂乱的语言中提炼观点。|
|主要处理工具|布局感知的PDF解析器（如PyMuPDF, Amazon Textract），能完美提取表格和章节。|自然语言处理工具包，用于情感分析、关键词提取。|工具的选择由数据的形态决定。"律师"的案卷是格式严谨的卷宗，而"心理学家"面对的是自由流淌的对话。|
|核心切片策略|结构化切片。严格按照"第X条第Y款"或财报的"Item 1A. Risk Factors"来分割，绝不跨越。|语义切片。忽略段落，根据语义相似度来聚合内容。所有关于"电池续航"的抱怨，无论用词如何，都应被归为一类。| "律师"依赖的是法条的明确边界，而"心理学家"寻找的是思想的内在关联。|
|元数据利用|强制性、结构化元数据。例如：{"contract_id": "C2023-001", "clause": "8.1a", "effective_date": "2023-01-01"} 。|描述性、情境化元数据。例如：{"customer_id": "U12345", "sentiment": "negative", "product_line": "Stardust", "timestamp": "..."} 。|元数据是各自领域实现精确检索的钥匙。"律师"靠它按图索骥，"心理学家"靠它筛选案例。|


# 解锁专家小队的"武器库"：核心策略通俗解析
在前面的表格中，我们为不同的小队配置了各自的"核心切片策略"。这些名词听起来可能有些距离感，但它们的思想都非常直观。让我们用生动的比喻来解锁这些"武器"的真正威力。

### 1. 结构化切片 (Structural Chunking)
一句话解释：按照文档作者预设的结构（章节、标题、列表）来进行切分。

生动比喻：想象你在拆解一个精密的乐高模型。你不会用锤子把它砸成大小相近的碎块，而是会按照说明书的步骤，把"驾驶舱"、"机翼"、"起落架"等完整的部件小心地分离开。结构化切片就是这位遵循说明书的"模型大师"，它尊重作者通过标题（如# ##）和格式赋予文档的原始逻辑，确保每个切片都是一个有意义的、完整的"部件"。

应用案例：

原始Markdown文本:

<img width="746" height="361" alt="image" src="https://github.com/user-attachments/assets/2e61c481-7064-4e9a-8302-bc50bec2e14a" />

以下是提取的文字内容：
- 召回策略 (如何使用):
  - 工作流解析:
    1. 用户查询: "请介绍一下RAG切片的重要性"
    2. 系统执行:
```
# 伪代码
retriever.search(
  query="RAG切片的重要性",
  metadata_filter={
    "Header 2": {"contains": "切片"}
  }
)
```
    
    3. 第一步: 元数据过滤。系统不是在整个知识库里进行大海捞针式的搜索，而是先通过结构化查询，快速筛选出所有元数据中 Header 2 字段包含"切片"的文本块。在这个案例中，只有块2被选中。
    
    4. 第二步: 语义搜索。系统仅在块2这个极小的范围内，进行语义相关性计算，最终精准返回结果。
  - 核心优势: 效率与精度的双重提升。先通过元数据"修剪"掉大量不相关的"树枝"，再对少数最可能的"树叶"进行精细的语义分析。这极大地降低了搜索范围，避免了其他章节中可能出现的、但相关性不高的"切片"一词的干扰。
- 核心优势: 效率与精度的双重提升。先通过元数据"修剪"掉大量不相关的"树枝"，再对少数最可能的"树叶"进行精细的语义分析。这极大地降低了搜索范围，避免了其他章节中可能出现的、但相关性不高的"切片"一词的干扰。
  - 结构化切片召回流程
    - 用户查询 
    - 全量知识库
      - 数百万块
    - 元数据过滤
      - 筛选出少量
        - 候选块
        - 语义搜索
          - 在候选中
            - 精准匹配
              - 精准结果

结构化切片的召回流程

用户查询，和全量知识库通过原数据过滤，筛选出少量的候选块，语义搜索，在候选中精准匹配，精准结果

### 2. 语义切片 (Semantic Chunking)
一句话解释：根据内容的主题和意思来决定在哪里切分。

生动比喻：想象你正在整理一场大型派对的所有谈话录音。你不会按每隔五分钟切一段，而是会仔细听内容，把所有关于"最近的电影"的讨论放在一起，所有关于"假期计划"的讨论放在另一堆。语义切片就是这位懂社交的"派对组织者"，它不在乎文字表面的长度或格式，只关心"这段话跟上一段话是不是在聊同一个话题？"，从而在话题自然转变的地方切分。


- 召回策略 (如何使用):
  - 工作流解析:
    1. 用户查询: "这款笔记本电脑用起来会不会很烫? "
    2. 系统执行:
```
# 伪代码
vector_store.similarity_search(
    query="这款笔记本电脑用起来会不会很烫? "
)
```
    3. 向量匹配: 系统将用户的口语化提问"用起来会不会很烫"转换成一个查询向量。这个向量在语义空间中，会非常接近于描述"散热系统"、"风扇噪音"、"C面温度"的那个文本块的向量，即使查询中完全没有出现这些原文的关键词。
  - 核心优势: 强大的泛化能力和概念理解能力。它超越了关键词匹配的局限，能够真正理解用户的"意图"。即使用户问的是"散热好不好"、"风扇吵不吵"，它都能准确地找到相关的负面评价文本块。




### 3. 父文档检索器 (Parent Document Retriever)
- **一句话解释**：检索时先找到最精确的小信息点，然后返回包含这个点的、更大的上下文。
- **生动比喻**：你在图书馆的一本书里找到了一句让你醍醐灌顶的话（子块）。但要真正理解它，你需要它所在的那一整个段落，甚至那一整章（父块）。父文档检索器就是那位贴心的图书管理员，当你指着那句话时，他不会只把那句话抄给你，而是会把整本书翻到那一页，递给你说：“请看，这是它的完整上下文。” 这个策略完美地结合了查找的“精确性”和理解的“全面性”。 
- **应用案例**：
  - 用户查询: "API的超时参数 timeout 单位是什么？" 
  - 检索到的子块: 一个非常小的、精确的文本块 -> timeout 参数的单位是秒（s）。 
  - 返回给LLM的父块: 包含上述子块的整个函数文档 -> 
```
### 函数: connect_to_server(host, port, timeout=30)
连接到指定服务器。
- host (str): 服务器地址。
- port (int): 服务器端口。
- timeout (int): `timeout`参数的单位是秒（s）。如果连接在此时间内未建立，将引发超时错误。
```
- **召回策略 (如何使用)**：
  - **工作流解析**：
    1. 用户查询: "API的超时参数 timeout 单位是什么？" 
    2. 第一步：在子块中精确查找。系统在专门存储“子块”的向量数据库中进行语义搜索，由于子块小而精，查询向量能精准地匹配到内容为" timeout 参数的单位是秒（s）"的子块。这个子块自身携带一个指向其父块的ID。 
    3. 第二步：凭ID提取父块。系统拿到这个ID后，从一个独立的文档存储（Docstore，可以是一个简单的键值对数据库）中，提取出完整的“父块”——也就是整个函数的详细文档。 
    4. 最终返回: 将这个信息量丰富的父块，而不是那个简短的子块，提供给LLM进行回答。 
  - **核心优势**：兼得鱼和熊掌。我们利用小块的嵌入精确性来确保“找得准”，同时又利用大块的上下文完整性来确保LLM“答得好”。它完美解决了“小块信息不足”和“大块语义模糊”这一核心矛盾。
 
  <img width="505" height="1223" alt="image" src="https://github.com/user-attachments/assets/512d1da5-6278-4412-aa1a-be71e06c75e9" />

<img width="432" height="872" alt="image" src="https://github.com/user-attachments/assets/8dd25ede-8db1-4811-b6e7-bdb5bea754ee" />


<img width="463" height="915" alt="image" src="https://github.com/user-attachments/assets/0d0f8857-0788-40a1-8b7c-692828da463d" />

### 4. 元数据增强切片 (Metadata-Augmented Chunking)
- **一句话解释**：给每个切片贴上描述其属性的“标签”。 
- **生动比喻**：想象你在搬家，把所有东西都装进了大小一样的箱子里。如果没有标签，你将陷入混乱。但如果你给每个箱子都贴上标签——“厨房用品|易碎|2023年冬”或“卧室衣物|夏季|小件”（这就是元数据），你就能快速找到任何东西。元数据增强切片就是这位严谨的“整理师”，它给每个文本块都附上了身份信息（如来源、日期、作者、所属章节），让你可以进行“数据库式”的精确筛选，而不仅仅是模糊的语义搜索。 
- **应用案例**：
  - 一个文本块的内容: "本季度的主要增长动力来自于'星尘'产品线在亚太市场的强劲表现。" 
  - 附加的元数据:
```
{
  "source_doc": "2023_Q3_Earnings_Call_Transcript.pdf",
  "page_number": 5,
  "author": "CFO Jane Doe",
  "publish_date": "2023-10-26",
  "security_level": "Internal-Confidential"
}
```
  - 带来的能力：你可以发起这样的查询 -> "只搜索第三季度的财报电话会议记录中，由CFO提及的关于'星尘'产品的内容"。 
  - **召回策略 (如何使用)**：
    - **工作流解析**：
      1. 用户查询: "CFO在第三季度的财报会议上，对'星尘'产品线有何评论？" 
      2. 系统执行（混合搜索）:
```
# 伪代码
retriever.search(
  query="对'星尘'产品线有何评论",
  metadata_filter={
    "and": [
      {"source_doc": {"equals": "2023_Q3_Earnings_Call_Transcript.pdf"}},
      {"author": {"equals": "CFO Jane Doe"}},
      {"security_level": {"in": ["Public", "Internal-Confidential"]}}] // 假设还要检查权限
  }
)
```
      3. 第一步：元数据预过滤 (Pre-filtering)。向量数据库首先根据 metadata_filter 中的严格条件，进行一次闪电般的结构化搜索，将数百万个文本块瞬间过滤到可能只有几十个符合条件的块。 
      4. 第二步：在子集上进行语义搜索 (Semantic Search on Subset)。然后，仅在这几十个块的小范围内，执行向量相似度搜索，找到与“对'星尘'产品线有何评论”语义最相关的块。 
    - **核心优势**：极致的性能与精度。这是目前工业界最强大和常用的检索模式之一。它将结构化数据库查询的“确定性”和向量搜索的“模糊语义匹配能力”完美结合，使得在海量、复杂的企业知识库中进行安全、精确、高效的检索成为可能。 
    - **元数据增强切片召回流程（混合搜索）过滤条件的来源**：
      - 结构化切片提供结构元数据（e.g., 章节, 标题） 
      - 外部信息增强增强元数据（e.g., 作者, 日期） 
      - 知识库：数百万已标记的块 
      - 用户查询先经过 Step 1: 元数据预过滤，过滤后范围锐减（例如：仅剩几十个块 ）  ，后续流程图未完整展示  。 

<img width="943" height="1096" alt="image" src="https://github.com/user-attachments/assets/be471e0a-9018-4fb7-a839-416bce507dc3" />

## 5. 其他重要策略
特定模态切片 (Modality-Specific Chunking)：这是"多才多艺的分析师"，能识别出文本中的表格、图片，将它们作为特殊对象单独处理，而不是当成无意义的文字。

滑动窗口切片 (Sliding Window)：这是"小心谨慎的读者"，在读下一页之前，总会回头看一眼上一页的最后几个词，以确保意思能完全衔接上。它通过让相邻的块有少量重叠，来避免在边界处丢失上下文。

理解了这些核心策略的本质思想，你就能更好地理解为什么我们将它们如此配置，以及如何在自己的项目中灵活运用它们。


您在交流中提出的"由AI创建知识管理团队"的观点，正是通往这个未来的关键。
这意味着我们的"智能知识路由与调度中心"，将从一个静态的规则引擎，升级为一个具备生命周期管理能力的、活的AI系统。它通过以下方式，让"专家小队"实现真正的自动化：

自动化数据准入与分类 (Automated Data Onboarding & Classification):


系统的前端是一个AI分类器。当任何新文档（无论是邮件、报告还是聊天记录）进入企业知识库时，该分类器会分析其内容和结构，自动判断它属于哪个"知识团队"，并将其发送到对应的专家RAG处理管道中。这就实现了知识摄取的自动化，无需人工干预。


动态策略优化与自适应 (Dynamic Strategy Optimization & Adaptation):

系统会持续监控每个知识团队的检索性能。如果发现"产品/API小队"的检索准确率下降，系统可以自动进行"A/B测试"：尝试用一种新的切片策略（例如，从递归切片切换到父文档检索器）重新索引一小部分数据，对比新旧策略的用户反馈，并最终将更优的策略无缝部署到整个团队。这是一个自我优化的闭环。


新知识领域的自动发现与创建 (Automatic Discovery & Creation of New Domains):

这是最激动人心的部分。当系统中出现大量无法被现有分类器识别的新类型文档时（例如，公司开始大量撰写关于"ESG可持续发展"的报告），系统能够通过聚类算法识别出这是一个新兴的知识簇。此时，它可以自动"创建"一个新的"ESG知识小队"，为其选择一个最稳妥的基准切片策略（如递归切片），并开始独立的索引流程，同时提醒人类管理员对这个新团队进行审核和微调。

通过这种方式，整个RAG系统就从一个需要手动维护的静态架构，演变成了一个能够适应企业知识体系不断变化的、真正意义上的"智慧生命体"。




